<!--
  Copyright 2018 The Distill Template Authors

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->

<!DOCTYPE html>
<!--[if IE lte 8]><script src="http://html5shiv.googlecode.com/svn/trunk/html5.js" defer></script><![endif]-->
<head>
  <script src="./template.v2.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel = "stylesheet" href="style.css">
  <meta charset="utf8">
</head>

<body>

  <d-front-matter>
    <script id='distill-front-matter' type="text/json">{
    "title": "EngramNCA: a Neural Cellular Automaton Model of Memory Transfer",
    "description": "Although \" extremely useful for visualizing high-dimensional data, t-SNE plots can sometimes be mysterious or misleading.",
    "published": "March 1, 2025",


    "authors": [
      {
        "author":"Etienne Guichard",
        "authorURL":"",
        "affiliations": [{"name": "Østfold University College", "url": "https://www.hiof.no/english/"}]
      },

      {
        "author":"Felix Simon Reimers",
        "authorURL":"https://www.hiof.no/iio/english/people/aca/felixsr/index.html",
        "affiliations": [
          {"name": "Østfold University College", "url": "https://www.hiof.no/english/"}
        ]
      },

      {
        "author":"Mia-Katrin Kvalsund",
        "authorURL":"https://www.mn.uio.no/fysikk/english/people/aca/mkkvalsu",
        "affiliations": [
          {"name": "University of Oslo", "url": "https://www.uio.no/english/"}
        ]
      },
      {
        "author":"Mikkel Lepperød",
        "authorURL":"https://lepmik.github.io/",
        "affiliations": [
          {"name": "Simula Research Laboratory, University of Oslo", "url": "https://www.simula.no/"}
        ]
      },
      {
        "author":"Stefano Nichele*",
        "authorURL":"https://www.nichele.eu/",
        "affiliations": [{"name": "Østfold University College, Oslo Metropolitan University", "url": "https://www.hiof.no/english/"}]
      }


    ],
    "_url": "https://etimush.github.io/EngramNCA/",
    "journal": "Github Preprint",
    "katex": {
      "delimiters": [
        {"left": "$$", "right": "$$", "display": false}
      ]
    }
  }</script>
  </d-front-matter>
  <d-title>
    <figure style="grid-column: page; margin: 1rem 0;"><video loop autoplay playsinline muted src="figures/banner.mp4"
        style="width:100%; border: 1px solid rgba(0, 0, 0, 0.2);" /></figure>
    <p><b>Left:</b> GeneCA trained to grow simple polygons through immutable gene encodings. These polygons are stable in time, exhibit individuality (strong morphological boundaries), and their genes can be combined to produce new out-of-training polygons.
      <b>Center:</b> GenePropCA trained to grow a lizard morphology by exploiting the gene embeddings of the GeneCA (left). The GeneCA cannot modify its own gene embedding, and the GenePropCA cannot modify the visible channels, yet the GenePropCA can learn to exploit the GeneCA gene embeddings and force it to draw a target morphology.
    <b>Right:</b> By adding immutable genes to the GenePropCA that neither it nor the GeneCA can modify, we can encode multiple target morphologies, where the GenePropCA can exploit the GeneCA genes to grow different morphologies.</p>
  </d-title>
  <d-byline></d-byline>

  <d-article margib-bottom: 0>

    <p style="color:#696969;font-size:13px;">Current version: draft v.0.1, Feb 2025 <br> *Corresponding author <a href="stefano.nichele@hiof.no" target="_blank">(stefano.nichele@hiof.no)</a> <br> Paper Repository: <a href="https://github.com/etimush/EngramNCA" target="_blank">GitHub</a> <br>PDF Preprint: <a href="https://arxiv.org/abs/2504.11855" target="_blank">(preprint)</a> <br> Published article: will be added here <br> Google Colab: <a target="_blank" href="https://colab.research.google.com/github/etimush/EngramNCA/blob/main/EngramNCA.ipynb">
  <img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/>
</a></p>

  </d-article>

<d-article class="center">


    <a class="marker" href="#section-1" id="section-1"></a>
    <h2>Introduction</h2>
<d-contents class="sticky">
  <nav class="l-text toc figcaption">
    <h3>Contents</h3>
    <div><a href="#section-1">Introduction</a></div>
    <div><a href="#section-2">Model(s)</a></div>
      <ul>
    <div><a href="#section-2.1">GeneCA</a></div>
    <div><a href="#section-2.2">GenePropCA</a></div>
    <div><a href="#section-2.3">EngramNCA - An Ensemble Model</a></div>
      </ul>
    <div><a href="#section-3">Hierarchical Growth Task</a></div>
      <ul>
    <div><a href="#section-3.1">Growing Coexisting Primitives</a></div>
    <div><a href="#section-3.2">Growing Morphologies from Primitives</a></div>
    <div><a href="#section-3.3">Growing Coexisting Morphologies</a></div>
      </ul>
    <div><a href="#section-4">Training Procedure</a></div>
      <ul>
    <div><a href="#section-4.1">GeneCA Training</a></div>
    <div><a href="#section-4.2">GenePropCA Training</a></div>
      </ul>
    <div><a href="#section-5">Results</a></div>
      <ul>
    <div><a href="#section-5.1">Growing Coexisting Primitives</a></div>
    <div><a href="#section-5.2">Growing Morphologies from Primitives</a></div>
    <div><a href="#section-5.3">Growing Coexisting Morphologies from Primitives</a></div>
    <div><a href="#section-5.4">Moving Primitives</a></div>
      </ul>
    <div><a href="#section-6">Related Work</a></div>
      <ul>
    <div><a href="#section-6.1">On Neural Cellular Automata</a></div>
    <div><a href="#section-6.2">Related to Memory Engrams</a></div>
      </ul>
    <div><a href="#section-7">Summary and Discussion</a></div>
  </nav>
</d-contents>
    <p>The currently most accepted theory of memory in biological and artificial brains is the synapses dogma <d-cite  key="mayford2012synapses"></d-cite>, that is,
        the place where information is stored is at synapses.  Therefore, it is believed that the storage of memories
        happens through changes in synaptic strengths <d-cite  key="cajal1894fine"></d-cite>. This view is challenged by emerging evidence that memory is also
        present privately within neural cells (and potentially other types of cells) <d-cite  key="abraham2019plasticity"></d-cite>, and synapses are merely a visible reverberation of such private memories  <d-cite  key="gold2021central"></d-cite>.
        Compelling examples are the evidence of memory transfer via injection of RNA extracted from trained aplysia into
        untrained animals <d-cite  key="Bedecarrats2018"></d-cite>, the memory transfer via a soup of trained planaria fed to untrained organisms <d-cite  key="mcconnell1967modern"></d-cite>, and the decapitation
        of planaria that retained long-term memories after head regeneration <d-cite  key="shomrat2013automated"></d-cite>. Such findings suggest that RNA transfer between cells can influence cellular functions and behaviors,
        including memory storage and transmission. Practically, cells can transfer RNA molecules to their surroundings via extracellular vesicles (membrane-bound particles)
        that encapsulate RNA and other molecules, or by tunneling nanotubes that form a direct physical connection between cells.
    </p>

    <p>In this work, we propose a Neural Cellular Automaton (NCA) <d-cite  key="mordvintsev2020growing"></d-cite> model that allows for private memory storage
        within cells and memory transfer across cells.  By replicating such memory mechanisms, we might equally be able to enable richer intercellular communication
        and more reliable generation of complex patterns, compared to classical NCAs that rely exclusively on publicly visible cell states. We name this new model
        EngramNCA, with reference to <i>engram</i> which in neuropsychology indicates the physical substrate of memory in biological organisms or, in other words,
        the means by which memories are stored.  </p>
    <p>We extend the NCA model in two ways:</p>
    <ul style="margin-top: 0">
<li>Each cell has a publicly visible state (comprised by a certain number of public CA channels) that can be accessed by neighboring cells and used as available information for computing cell state updates. This is akin to information transmitted through synapses to neighboring cells.</li>
<li>Each cell has a private memory (comprised by a certain number of private CA channels) that is visible only to the cell itself. This represents some sort of internal state stored more permanently in a cell, that can be possibly transmitted or made available to other cells in a manner akin to RNA transfer (or other plausible molecular transfer mechanisms).</li>
</ul>

    <p>When CA cells update their state, their internal neural network (a homogeneous neural network with identical
        weights for all cells) acts upon the visible channels in the neighborhood, in addition to the cell’s own private
        memory. The result is the interplay of the visible component and the (private) memory stored within the cell.
    </p>
    <p>As such, a focus is to train the NCA to utilize its cells internal memory to full capacity, since it is not directly accessible by other cells.
        Therefore, it has to learn to produce a reverberation of it through its visible channels in order to carry out
        the collective computation in coordination with the neighbors.
    </p>

    <p>This coordination is achieved by first training an NCA to grow from a seed cell to a set of primitive morphologies.
        The only cell initially containing the genetic information (private memory) representing the target morphology is the seed cell itself.
        Each morphology is encoded by a different private representation. Therefore, this NCA has to learn to achieve the global task only through its visible channels.
        The neural network weights of this first NCA are then frozen and do not change. We name this first neural network GeneCA.
    </p>

    <p>Subsequently, another NCA is trained in addition to the previous, which does not manipulate and change the visible
        information of cells, but can only change their private genetic memory, i.e., a set of private channels. As such,
        it has to learn a mechanism to regulate the private information such that the previously learned primitive morphologies
        (or their combination) can be utilized and activated at the right time and in the right place. We name this second neural network GenePropCA, short for GenePropagationCA.</p>

    <p>The GenePropCA mechanism is an abstraction for RNA molecular transmission between cells, which provides a form of functionality transfer.
        The transmitted functionality is stored in the cell’s internal memory and, in turn, affects the behavior of the GeneCA (the cell’s visible state). </p>

    <p>Note that in biological systems, the two types of information transfer, i.e., synaptic transfer and RNA transfer,
        may happen at two different timescales. Typically, spikes through synapses are transmitted faster than RNA transfers.
        However, in our framework we have tested with different timescales (basically running the GeneCA faster than the GenePropCA,
        or vice versa) without affecting the functionality. Overall, the system learns to adjust the rate of updates from one of the two NCA to solve the task at hand.

    </p>

    <p>We test the proposed NCAs on different morphogenetic tasks, including the growth of simple yet stable primitives,
        out-of-distribution mixtures of primitives, more complex morphologies obtained by the combination of basic primitives,
        and moving primitives such as Lenia gliders. </p>




    <a class="marker" href="#section-2" id="section-2"></a>
    <h2>Model(s)</h2>
    <p>In this section , we introduce the changes to the overall architecture from <d-cite  key="mordvintsev2020growing"></d-cite>,
        and detail the implementation of the two new models (GeneCA snd GenePropCA, respectively), that form the backbone of the EngramNCA model, including illustrations of their specific architecture and
        how they interact with each other.
    </p>

    <p>Taking inspiration from RNA memory transfer observed Planarians and Aplysia, we augment the NCA hidden state with a "private tape".
    Instead of extending the classic NCA model by appending the tape to the hidden states, we choose to sacrifice hidden states by privatizing them, this ensures that any
    improvements seen are not due to an increase in model size (please see Appendix 1 for masking of hidden channels to investigate task deterioration with less available channels). The hypothesis here is that the private tape augmentation can be exploited to encode different modalities of behaviour,
    such as growing different shapes or representing different computations. An illustration is provided in <a href="#figure-augment" class="figure-link" data-target="figure-augment"></a>, where the channels of the cell are represented, including the RGB
    channels, the alpha channel, three additional channels, plus three gene channels (G1,G2, and G3) representing the private tape.

    <figure style="text-align: center; margin: 4rem 0;" id="figure-augment"><img playsinline src="figures/gene.drawio.svg";
          style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>NCA augmentation through gene embedding channels, where the channels of the cell are represented, including the RGB channels, the alpha channel, three additional channels, plus three gene channels (G1,G2, and G3) representing the private tape.</figcaption>
    <p><br></p>
    <p>We chose to encode different "primitives" in the tape through binary representation. These primitives can consist of simple shapes such as convex polygons or
    more complex, convex, compound shapes such as body segments of a lizard emoji. Examples of encodings are represented in <a href="#figure-embed" class="figure-link" data-target="figure-embed"></a>  and <a href="#figure-embedliz" class="figure-link" data-target="figure-embedliz"></a>, where three basic geometric morphologies and lizard parts are given, respectively.</p>
    <figure style="text-align: center; margin: 4rem 0;" id="figure-embed" ><img playsinline src="figures/embedding.drawio.svg";
          style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption> Binary embedding of geometric morphologies and their respective encoding.</figcaption>
     <p><br></p>      
    <p>The tape length has to be chosen such that <d-math>2^{gene\_channels}   </d-math> is greater or equal to the number of primitives. This ensures that,due to the binary representation, there are enough
    distinct binary encodings for each primitive. However, due to reasons that will be discussed later, it is often preferable to have a buffer of genes that are not used
    in the binary encoding. There is a delicate balance between the number of gene bits and shared hidden channels that needs to be reached as privatisation of channels
    ensures a performance penalty (see Appendix 1 for details). </p>

    <figure style="text-align: center; margin: 2rem 0;" id="figure-embedliz"><img playsinline src="figures/LizEmbeddings.drawio.svg";
          style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption> Binary embedding of lizard body sections and their respective encodings. </figcaption>



    <a class="marker" href="#section-2.1" id="section-2.1"></a>
    <h3>GeneCA</h3>


    <p>The first model (<a href="#figure-div" class="figure-link" data-target="figure-div"></a>), which we  name GeneCA, is tasked with learning the primitive embedding. It takes
    inspiration form the original NCA <d-cite key="mordvintsev2020growing"></d-cite> and is extended to also include a laplacian convolution filter as found in <d-cite key="mordvintsev2022growing"></d-cite>. Notably,
        the parameters only produce a partial cell-state update-vector that comprises all non-gene channels. The gene channels are cloned and appended to the update vector after the stochastic
    update step to prevent degradation over time. This leads to no change or propagation of gene channel information throughout the NCA cell. It is worth to note that, since the only
        living cell that is initialized at the beginning of each run is a single seed cell, all cells besides the seed cell have no information in their gene channels (i.e., all zeros).
        This means that the GeneCA learns to grow the primitive morphologies from a seed cell without relying on a mechanism to transmit the gene channel information to other cells.
        Additionally, this signifies that cells do not practically observe the private tape of neighboring cells.</p>

      <figure style="text-align: center; margin: 2rem 0;" id="figure-div">
    <img playsinline src="figures/Gene.drawio.svg" style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" />
    <figcaption>One step of the GeneCA</figcaption>
    </figure>


    <a class="marker" href="#section-2.2" id="section-2.2"></a>
    <h3>GenePropCA</h3>

    <p>The GenePropCA model (<a href="#GeneProp" class="figure-link" data-target="GeneProp"></a>) is tasked with exploiting the gene embedding learned by the GeneCA.
    By conditioning the primitive growth in the GeneCA to a specific embedding, these embeddings now carry latent information about the primitives. We assume that the latent information
    in each embedding can be modified to produce out-of-distribution behaviour, thus allowing the GenePropCA to both propagate and modify the genes to achieve a desired goal.
    The architecture of the GenePropCA is similar to that of the GeneCA, where the neural network parameters produce a partial cell state update. In this case, only the genes channels are updated. Like in
    the GeneCA, the unmodified cell states are cloned and appended after the asynchronous partial update, leading to the GenePropCA having no influence over non-gene channels. </p>

    <figure style="text-align: center; margin: 2rem 0;" id="GeneProp"><img playsinline src="figures/GeneProp1.drawio.svg"
      style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>One step of the GenePropCA</figcaption>




    <a class="marker" href="#section-2.3" id="section-2.3"></a>
    <h3>EngramNCA - An Ensemble Model</h3>

    

    <p>The EngramNCA ensemble model (<a href="#Enseble" class="figure-link" data-target="Enseble"></a>) uses the GeneCA and GenePropCA to produce the final morphology. The GeneCA works without the GenePropCA and will produce the primitives. The
    GenePropCA is dependent on the GeneCA as its parameters are trained to manipulate the GeneCA dynamics. At step N, the state of the CA is passed to the GeneCA, where it only modifies the visible and hidden channels
    to produce an intermediate state, the intermediate step is then passed to the GenePropCA, where only the gene encoding channels are modified to produce step N+1. The idea here is for the
    GenePropCA to learn to exploit the gene embedded dynamics of the GeneCA to produce more complex morphologies than that found in the GeneCA.</p>
    <p>For a formal mathematical definition of the proposed models, including GeneCA, GenePropCA and the ensemble model EngramNCA, together with the training procedure, please refer to the relative section in Appendix 2)</p>

    <figure style="text-align: center; margin: 2rem 0;" id="Enseble"><img playsinline src="figures/Enseble.drawio.svg"
      style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>One step of the ensemble, GeneCA + GenePropCA</figcaption>


    <a class="marker" href="#section-3" id="section-3"></a>
    <h2>Hierarchical Growth Task</h2>

    <p>The traditional NCAs presented in <d-cite key="mordvintsev2020growing">"</d-cite>  uses the neural-network
    parameters to encode the desired behaviour. In effect, the neural-network can be seen as the genome for the morphology, where for each distinct morphology a new NCA needs to be trained.
    This makes it particularly difficult to have coexisting morphologies, or even just coexisting dynamics, existing on the same lattice, as the multiple NCAs end up interfering with each other.</p>

    <p>Our model presents a possible solution to this problem by tying the morphological result to an unchanging seed cell. In this way, we hypothesize that
    the NCA learns general growing dynamics necessary for any morphology, alongside encoding-specific dynamics for the details of the morphology.  </p>

    <a class="marker" href="#section-3.1" id="section-3.1"></a>
    <h3>Growing Coexisting Primitives</h3>

    <p>The first step in the hierarchical growth task was to grow coexisting morphologies. In effect, this means to grow multiple distinct morphologies using the same set of NCA (our GeneCA) parameters. Much like the original growth task as described in <d-cite key="mordvintsev2020growing">"</d-cite>, the
    multiple morphologies should be bounded and stable across time, with their shape unchanging once fully generated.
        We conducted multiple experiments including; many high-complexity primitives (lizard body parts, <a href="#AllPrims" class="figure-link" data-target="AllPrims"></a>, left), fewer medium-complexity primitives (basic polygons, <a href="#AllPrims" class="figure-link" data-target="AllPrims"></a>, middle), and fewer low-complexity shapes (vertical and horizontal lines, <a href="#AllPrims" class="figure-link" data-target="AllPrims"></a>, right). </p>

    <figure style="text-align: center; margin: 2rem 0;" id="AllPrims"><img playsinline src="figures/all_prims_2.drawio.svg"
      style="width:70%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Left: All lizard body parts used in training a GeneCA. Middle: All polygons used in training a GeneCA. Right: Vertical and horizontal lines used in training a GeneCA.</figcaption>


    <a class="marker" href="#section-3.2" id="section-3.2"></a>
    <h3>Growing Morphologies from Primitives</h3>

    <p>From a trained GeneCA we then trained the GenePropCA to exploit the latent-space embeddings that the genes now represent. The three different
        GeneCA mentioned previously where used to test the GenePropCAs capabilities under different circumstances. A high primitive count, low combinatorial problem in growing the lizard (<a href="#LizFract" class="figure-link" data-target="LizFract"></a>, left), where there is only one valid combination. A low primitive count, high combinatorial
    problem in growing a fractal-like shape (<a href="#LizFract" class="figure-link" data-target="LizFract"></a>, right) from vertical and horizontal lines. Finally, a combination of the two, by growing a lizard from basic polygons.</p>

    <figure style="text-align: center; margin: 2rem 0;" id="LizFract"><img playsinline src="figures/liz_fract.drawio.svg"
      style="width:70%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Left: Full Lizard morphology used in training the GenePropCA. Right: Fractal-like morphology used in training the GenePropCA .</figcaption>



    <a class="marker" href="#section-3.3" id="section-3.3"></a>
    <h3>Growing Coexisting Morphologies</h3>

    <p>For final step in the hierarchy, we chose to explore  growing multiple morphologies from the same GeneCA and GenePropCA. This was accomplished by extending the model one hierarchy up, and imbuing the GenePropCA  with its own meta-genes, that it could see, but  neither it nor the GeneCA could modify, and using those meta-genes to encode for entire morphologies.</p>



    <a class="marker" href="#section-4" id="section-4"></a>
    <h2>Training Procedure</h2>
    <p>In this section we provide a  description of the training procedure,  including two distinct training phases, a special pooling method to train multiple primitives at one, and how the GeneCA weights are frozen when training the GenePropCA.</p>

    <p> The loss function used for training on all the images is the Pixelwise-MSE, as used in <d-cite key="mordvintsev2020growing"></d-cite>:</p>

    <d-math style="text-align: center; margin: 2rem 0;">

      PixelWiseMSE = \frac{1}{H \times W \times C} \sum_{i=0}^{H} \sum_{j=0}^{W} \sum_{k=0  }^{C} \left( I(i, j, k) - \hat{I}(i, j, k) \right)^2

    </d-math>

    <p>Where <d-math>H,W,C</d-math> are the dimension of the image, <d-math>I</d-math> is the reference image, and <d-math>\hat{I}</d-math> is the final state of the NCA.</p>

    <a class="marker" href="#section-4.1" id="section-4.1"></a>
    <h3>GeneCA Training</h3>
    <p>GeneCA training is similar to the pool-training procedure presented in <d-cite key="mordvintsev2020growing"></d-cite>. However, to enable the gene encoding of multiple primitives,
    each gene-primitive pair is given its own pool to sample from and update. Additionally, the target image becomes a target batch consisting of n-repetitions of each image,
    where n is a factor of the batch size. This is done so that multiple images per batch can be considered in the loss. It is important to keep the batch size as a multiple of the number of primitives to avoid training bias towards one primitive. <a href="#multiTraining" class="figure-link" data-target="multiTraining"></a> illustrates the training procedure for batch-multi-image training under the GeneCA scheme.</p>

    <figure style="text-align: center; margin: 2rem 0;" id="multiTraining"><img playsinline src="figures/Training.drawio.svg"
      style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Training loop for multi-image batch training</figcaption>

    <a class="marker" href="#section-4.2" id="section-4.2"></a>
    <h3>GenePropCA Training</h3>
    <p>GenePropCA training uses the same batch training technique as the GeneCA. We typically only train a single morphology, however multiple morphologies can be trained by
    sacrificing more channels to act as "meta genes". These meta genes are unaffected by both the GeneCA and GenePropCA. During the training of the GenePropCA the GeneCA weights are frozen,
    though their gradient contribution during the growth process is still used when backpropagating the loss to the GenePropCA. This ensures the GenePropCA's dynamics are
        conditioned on those of the GeneCA. <a href="#dualtraining" class="figure-link" data-target="dualtraining"></a> shows the GenePropCA training with GeneCA frozen weights.</p>
     <figure style="text-align: center; margin: 2rem 0;" id="dualtraining"><img playsinline src="figures/training_prop.drawio.svg"
      style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Training loop for GenePropCA. The GeneCA weights are frozen, yet still contribute to the gradient computations, making the GenePropCAs behaviour dependent on the GeneCA.</figcaption>
    <a class="marker" href="#section-5" id="section-5"></a>
    <h2>Results</h2>
    <p>The model was tested with different configurations, and below are the results for our experiments. Generally, the NCA has a size of 30 x 30, there are 16 channels in total of which the first four are the alpha value and the three color channels. Of the remaining 12 hidden channels, eight channels were privatized, i.e. could be read but not be altered by the GeneCA. </p>

    <a class="marker" href="#section-5.1" id="section-5.1"></a>
    <h3>Growing Coexisting Primitives </h3>

    <p>Three primitives were chosen as target shapes: A blue square, a green circle and a red triangle. Those primitives have a corresponding one-hot encoding in the private tape. The GeneCA was trained to update the public channels of the CA such that the right primitive is formed around the seed cell. It is important to note that there is no gene propagation at this point, only the update of the public channels that the GeneCA calculates based on the available private and public channels. </p>
    <p>During test time, cells of the CA are picked as seed cells, and their private tape is altered. </p>

    <p>In the top of <a href="#growing-prims" class="figure-link" data-target="growing-prims"></a> we show how the binary encodings of the three primitives are assigned to three different cells in the CA, with the distance between them being great enough to avoid interactions between cells belonging to different primitives. Starting from the seed cell, the shapes and their color form over a number of update steps. Afterwards, they remain stable. </p>
    <figure style="text-align: center; margin: 2rem 0;" id="growing-prims"><video loop autoplay playsinline muted width="640px"; src="figures/Primitives.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing simple primitives.</figcaption>
    <p></p>
    <p> <a href="#individuality-demo" class="figure-link" data-target="individuality-demo"></a> shows what happens if seed cells are placed in such proximity to each other that the resulting primitives would normally overlap.
        As can be seen, the shapes remain largely distinct. Especially shapes of the same kind have neither overlap nor mixing and instead a border
        can be visually seen. Circles placed in proximity to each other can for example be seen to form a comb-like structure (top of <a href="#individuality-demo" class="figure-link" data-target="individuality-demo"></a>).
        If shapes of different kinds meet, the distinction is not always as clear and some interactions between different primitives can lead to a
        mixing of colors, as can be seen in the bottom of <a href="#individuality-demo" class="figure-link" data-target="individuality-demo"></a>. Still, a distinction can be made and no primitive takes over another primitive.
        This happens without such cases occurring during training. </p>
    <figure style="text-align: center; margin: 2rem 0;" id="individuality-demo"><video loop autoplay playsinline muted width="640px"; src="figures/Individuals.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Untrained behaviour: primitives displaying strong individuality.</figcaption>
    <p></p>
    <p>Only the three one-hot encodings were used during training, but it is possible to deviate from this during test time and to use different binary arrays as the private encodings of the seed cell.
        This essentially means that there is a mixture of genes. As can be seen in <a href="#primitive-mixing" class="figure-link" data-target="primitive-mixing"></a>, this leads to the growth of corresponding mixed forms. It can be seen that the shape of those forms is a
        distorted overlap of the primitives while the color ranges from the pure color of the primitives to the mix of the two colors. The primitives dominate the developing form in those areas where
        the other primitive is not growing, hence the combination of circle and square leads to most mixing. After a developmental period, the forms remain stable. This stability remains for any form of
        encoding mixing and seems to be bound by the maximum size of the primitives. </p>

    <figure style="text-align: center; margin: 2rem 0;" id="primitive-mixing"><video loop autoplay playsinline muted width="640px"; src="figures/Mixed.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Untrained behaviour: out-of-training generative capabilities from mixing genes.</figcaption>
    <p></p>
    <p>The experiments were repeated with body parts of the lizard image as primitives as can be seen in <a href="#body-part-prims" class="figure-link" data-target="body-part-prims"></a>. As those were more than three parts, the encoding is not one-hot anymore. As before, placing a seed cell with the corresponding encoding
        leads to the growth and stable persistence of primitives, even though those have more complex shapes and colorings. </p>

    <figure style="text-align: center; margin: 2rem 0;" id="body-part-prims"><video loop autoplay playsinline muted width="640px"; src="figures/body_parts.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Lizard body parts primitives.</figcaption>
    <p></p>
    <p>Lastly, very simple unicolor vertical and horizontal lines were used as primitive as is depicted in <a href="#line-prims" class="figure-link" data-target="line-prims"></a>. This is the setup for later experiments. </p>

     <figure style="text-align: center; margin: 2rem 0;" id="line-prims"><video loop autoplay playsinline muted width="640px"; src="figures/horiz_vert.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Horizontal and vertical line primitives.</figcaption>




    <a class="marker" href="#section-5.2" id="section-5.2"></a>
    <h3>Growing Morphologies from Primitives </h3>

    <p>At the next experimental step, the GenePropCA was included. The attempt was to grow whole morphologies, while the GeneCA weights where frozen on growing primitives.</p>
    <p>In the lizard example, the GenePropCA was trained as described above with the initial seed cell containing the gene encoding for the torso primitive and the GeneCA being trained
        on primitive body parts of the whole lizard (legs, head, torso, tail). As can be seen in <a href="#liz-from-parts" class="figure-link" data-target="liz-from-parts"></a>, the torso of the lizard is grown first, but the CA then continues to grow the limbs, tail and head. Deactivating
        the GenePropCA after the lizard is finished growing does not lead to a collapse, rather the lizard maintains its shape under the control of the GeneCA. </p>
    <figure style="text-align: center; margin: 2rem 0;" id="liz-from-parts"><video loop autoplay playsinline muted width="640px"; src="figures/Growing_from_torso.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing the lizard morphology from the torso.</figcaption>
    <p></p>
    <p>The experiment was repeated, this time choosing the circle, square and triangle as primitives and the blue circle as the seed cell during the GenePropCA training. This was successful, as can be seen
        in <a href="#liz-from-shapes" class="figure-link" data-target="liz-from-shapes"></a>. Even if the GeneCA is not trained on all primitives occurring in the final lizard or even on primitives not derived from the target image at all, the GenePropCA
        is able to generalize and facilitate gene propagation that leads to the growth of the lizard, albeit with less quality as in the case described above for <a href="#liz-from-parts" class="figure-link" data-target="liz-from-parts"></a>. <a href="#liz-diff-start" class="figure-link" data-target="liz-diff-start"></a>
        shows that the choice of the seed cell does indeed matter, as the lizard will only grow successfully if the exact same seed as in the training of the GenePropCA is used.  </p>
    <p>Further experiments showed that different seeds, which were not used as primitives during the training of the GeneCA, can be used to train the GenePropCA to grow a lizard.  </p>
    <figure style="text-align: center; margin: 2rem 0;" id="liz-from-shapes"><video loop autoplay playsinline muted width="640px"; src="figures/GrowingLizardFast.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing the lizard from basic polygon morphologies.</figcaption>
    <figure style="text-align: center; margin: 2rem 0;" id="liz-diff-start"><video loop autoplay playsinline muted width="640px"; src="figures/GrowingMorpho_multi.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing the lizard from basic polygon morphologies.The lizard will not grow from a primitive it was not trained to grow from.</figcaption>
    <p></p>
    <p><a href="#grow-frac" class="figure-link" data-target="grow-frac"></a> depicts an experiment in which the simple primitives of unicolor vertical and horizontal lines are combined into a fractal-like shape with satisfying performance. This shows that the model can combine simple and few primitives into more complex
        forms consisting of many primitives in addition to combining complex and many primitives into less complex (complexity in the sense of the combination of primitives) forms consisting of few primitives, as was done before with the lizard. </p>

    <figure style="text-align: center; margin: 2rem 0;" id="grow-frac"><video loop autoplay playsinline muted width="640px"; src="figures/fract.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing a fractal-like shape from simple vertical and horizontal primitives.</figcaption>

    <a class="marker" href="#section-5.3" id="section-5.3"></a>
    <h3>Growing Coexisting Morphologies from Primitives </h3>

    <p>The final experiment in growing morphologies was to test whether the GenePropCA could additionally grow multiple morphologies. This was done by adding an extra channel as a meta-gene, that neither the GeneCA nor GenePropCA could modify and training the GenePropCA to grow separate morphologies depending on the meta-gene encoding and the starting seed cell encoding.</p>
    <p><a href="#2-morph" class="figure-link" data-target="2-morph"></a> shows the GenePropCA growing both a lizard morphology and a butterfly by exploiting the same GeneCA gene encodings. The overall quality of reproduction of the lizard has diminished, whilst the butterfly, a much simpler morphology, was reproduced better.</p>
      <figure style="text-align: center; margin: 2rem 0;" id="2-morph"><video loop autoplay playsinline muted width="640px"; src="figures/multi_morpho.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing both a lizard and a butterfly with the same GeneCA and GenePropCA. The quality of reproduction is reduced.</figcaption>

    <a class="marker" href="#section-5.4" id="section-5.4"></a>
    <h3>Moving Primitives </h3>

    <p>In contrast to the relatively simple task of growing morphologies, we wanted to test if the GenePropCA could exploit the embedding and learn the dynamics of
    a complex moving system. For this we chose to replicate the dynamics of a Lenia  <d-cite  key="Lenia2019"></d-cite> glider. Lenia itself is a form of continuous CA that can exhibit remarkable complexity.
    We chose a glider (<a href="#originalLenia" class="figure-link" data-target="originalLenia"></a>)  whose dynamics where non-trivial, where learning to replicate it
    would take more than simply memorising a simple translation in space. The GeneCA was trained on the first frame of the Lenia video. The GenePropCA was trained on a
    quasi-curriculum-style learning, where at certain checkpoints additional frames of the video are inserted into the training set until the five-hundreds frame. It is always trained from the first frame
    to the last frame of the training set in order, and loss was accumulated across all frames before backpropagation. The frame-by-frame loss accumulation is important here
    since -unlike growing morphologies- the time evolution of the NCA from state to state is important. As a comparison a standard NCA was trained using the same method, the parameter count
    of the standard NCA was selected such that it corresponds to the sum of total parameters between the GeneCA and the GenePropCA.</p>

    <figure style="text-align: center; margin: 2rem 0;" id="originalLenia"><img playsinline src="figures/original_lenia.gif"
      style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Original Lenia video.</figcaption>
    <p></p>

    <p><a href="#standardNCA" class="figure-link" data-target="standardNCA"></a> shows the result of training a standard NCA on five-hundred frames of the Lenia video. As can be seen, the standard NCA somewhat replicates the dynamics until a certain point, where the simulation falls apart. Possibly due to the NCA only learning to replicate the exact frames it saw and not learning the dynamics.</p>

    <figure style="text-align: center; margin: 2rem 0;" id="standardNCA"><img playsinline src="figures/standard_nca.gif"
      style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Standard NCA trained to replicate the video.</figcaption>
    <p></p>
    <p>(<a href="#movingGene" class="figure-link" data-target="movingGene"></a>) shows the result of training the GeneCA and GenePropCA on five-hundred frames of the Lenia video. As can be seen, our method yields visually closer results to the Lenia video. Additionally, the morphology is stable past the five-hundred frame mark, exhibiting signs of having learned more general dynamics that are stable in time.  Though not a perfect replication of the Lenia glider, the results are decent.</p>

    <figure style="text-align: center; margin: 2rem 0;" id="movingGene"><img playsinline src="figures/Gene_ca_moving.gif"
      style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Our method trained to replicate the video.</figcaption>

    <a class="marker" href="#section-6" id="section-6"></a>
    <h2>Related Work</h2>

    <a class="marker" href="#section-6.1" id="section-6.1"></a>
    <h3>On Neural Cellular Automata</h3>

    <p>Neural cellular automata (NCAs) merge the classical framework of cellular automata with modern deep learning by replacing hand-crafted update rules with neural networks that are optimized via gradient-based methods. Earlier studies in cellular automata (e.g., <d-cite  key="Wolfram2002"></d-cite>) established that simple local rules can lead to complex emergent behavior. Building on these ideas, <d-cite  key="mordvintsev2020growing"></d-cite> introduced the “Growing Neural Cellular Automata” model, which trains a convolutional network with gradient-based learning to iteratively update a grid so that, starting from a single seed, complex images emerge and can regenerate after damage.</p>
    <p>Seminal work by <d-cite  key="miller2004evolving"></d-cite> explored evolving self-repairing, self-regulating cellular automata to produce the “French flag” pattern, demonstrating how evolutionary algorithms can discover diverse rule sets for complex morphogenesis. <d-cite  key="nichele2017neat"></d-cite> extended morphogenetic CAs with neuro-evolution of neural networks as CA rules. <d-cite  key="pontescritical"></d-cite> showed a NCA evolved to criticality. This was further studied by <d-cite  key="Guichard2024"></d-cite>. <d-cite  key="kvalsund2024sensor"></d-cite> discussed NCA a model for a distributed neocortex. </p>

    <p>A range of extensions have broadened the capabilities of NCAs.<d-cite  key="randazzo2020self"></d-cite> explored self-classification tasks. <d-cite  key="hernandez2021neural"></d-cite> presented NCA Manifold, creating embedding spaces of different morphogenetic processes. <d-cite  key="tesfaldet2022attention"></d-cite> developed an attention-based NCA that integrates self-attention mechanisms into the update process, allowing each cell to dynamically focus on relevant features in its local neighborhood and capture longer-range dependencies. <d-cite  key="grasso2022empowered"></d-cite> proposed Empowered Neural Cellular Automata, incorporating an information-theoretic objective (empowerment) to promote robust, coordinated behaviors. <d-cite  key="palm2022variational"></d-cite> proposed Variational Neural Cellular Automata, a probabilistic generative model that captures diverse emergent dynamics through variational inference. <d-cite  key="mordvintsev2022growing"></d-cite> proposed an isotropic version of NCAs, while <d-cite  key="pande2023hierarchical"></d-cite> presented Hierarchical NCA to model emergent behaviors at different scales.</p>

    <p>Extensions in application domains further illustrate the versatility of the NCA framework. <d-cite  key="variengien2021towards"></d-cite> applied NCAs to evolve controllers for a cart-pole system. <d-cite  key="horibe2022severe"></d-cite> demonstrated the use of NCAs for regenerating soft robot morphologies, showcasing their potential for self-repair akin to biological regeneration. <d-cite  key="najarro2022hypernca"></d-cite> studied a hypernetwork approach, named HyperNCA, that grows artificial neural networks with a developmental process. More recently, <d-cite  key="Reimers2023"></d-cite> introduced a pathfinding NCA with local self-attention, training automata to collectively explore environments and locate energy sources. <d-cite  key="randazzo2024simulating"></d-cite> exploited an NCA as an evolvable plant biome. Very recently, Differentiable Logic Cellular Automata by <d-cite  key="Pietro-Miotti-Eyvind-Niklasson-Ettore-Randazzo-Alexander-Mordvintsev2025-jb"></d-cite> integrates differentiable logic gates with traditional neural cellular automata to achieve discrete, interpretable update rules while maintaining the benefits of gradient-based training.</p>

    <a class="marker" href="#section-6.2" id="section-6.2"></a>
    <h3>Related to Memory Engrams</h3>


    <p>One work that greatly inspired us is <d-cite  key="Pappadopoulos2023"></d-cite>, where the incorporation of additional channels to encode for different morphologies is discussed. Additionally, <d-cite  key="sudhakaran2022goal"></d-cite> proposes a goal-encoder which serves a similar function to our proposed GenePropCA, while <d-cite  key="bessonov2015model"></d-cite> shares a similar inspiration to our work and uses a cellular automaton as test-bench. Also, <d-cite  key="winge2023artificial"></d-cite> shares a rather similar inspiration, however they use neurons with cell memory and their execution is rather different. More broadly, we were greatly inspired by <d-cite  key="MitchellCheney2024"></d-cite> and <d-cite  key="HartlLevin2024"></d-cite>, arguing that living systems encode robust, adaptable generative models that guide development and regeneration. Such works emphasize that biological lineages accumulate “memory engrams”—latent representations that enable organisms to reliably rebuild form and function despite perturbations. This concept is central in our idea of EngramNCA, where the model leverages dual-channel memory (public and private states) to simulate the distributed storage and transfer of memory observed in biological systems.

</p>


    <a class="marker" href="#section-7" id="section-7"></a>
    <h2>Summary and Discussion</h2>
    <p>The prevailing paradigm in neuroscience has long held that memory is predominantly stored and transmitted through synaptic plasticity—the so‐called “synaptic dogma” <d-cite  key="Kandel2001"></d-cite>. This view posits that modifications in synaptic strength are the primary means by which information is encoded in neural circuits. However, a growing body of experimental evidence suggests that memory storage may also involve intracellular processes and molecular mechanisms. For instance, studies in Aplysia have demonstrated that injection of RNA extracted from trained animals into naïve counterparts can induce memory‐like changes, implying that molecular substrates may contribute to memory formation beyond traditional synaptic modifications <d-cite  key="Bedecarrats2018"></d-cite>. Similarly, research on planaria has shown that decapitated individuals can retain learned behaviors after head regeneration, further suggesting that memory may reside in non‐synaptic, cellular compartments (<d-cite  key="McConnell1962"></d-cite>; <d-cite  key="Shomrat2013"></d-cite>).


These findings have significant implications for both biological and computational models of memory. Whereas classical models emphasize network-level interactions and synaptic weight adjustments, recent work has increasingly focused on the roles of gene expression and intracellular signaling cascades in long-term memory storage (<d-cite  key="Kandel2014"></d-cite>). Insights from developmental biology also support this broader perspective; gene regulatory networks, for example, orchestrate complex morphogenetic processes (<d-cite  key="Davidson2006"></d-cite>), underscoring the potential for multi-timescale information transfer that integrates fast synaptic signaling with slower, gene-mediated processes.</p>

    <p>Inspired by these biological insights, emerging computational frameworks—such as the one proposed here and named EngramNCA—are exploring dual modes of information storage. In these models, the system is endowed with a bifurcated state representation: a publicly accessible channel that mirrors synaptic activity and a private channel that represents intracellular memory. This dual-channel approach reflects the biological separation between immediate synaptic signaling and slower molecular memory transfer, offering a more nuanced basis for capturing complex developmental and memory dynamics. Integrating biological principles of memory into computational models may ultimately pave the way for more robust and adaptable systems.

</p>

    <p> Our results suggest that having fixed memory portions in the cells makes for more stable expression of learned patterns. Moreover, our results show that the learned dynamic behavior of Lenia could be expressed more accurately using a private memory. This observation supports the proposed mechanism as a possible explanation for how memory could be stored in real bodies. More importantly, it also shows that cell memory could be a promising approach to having more stable distributed systems in AI. Stability is an open problem in AI, which is typically mitigated by pool-training. One avenue for future work is to use EngramNCA cell memory mechanisms when pool-training is not applicable. Additionally, we suggest that EngramNCA could suit more complex datasets such as the Abstraction and Reasoning Corpus (ARC) <d-cite  key="chollet2019measure"></d-cite>. </p>

    <p>Further, the EngramNCA model could provide valuable insights for neuroscience by offering a computational framework that aligns with emerging biological evidence of memory mechanisms beyond the traditional synaptic dogma. By demonstrating how systems with both publicly visible states and private internal memory can develop more stable patterns, hierarchical organization, and robust information transfer, this model suggests potential mechanisms for biological phenomena like memory retention after tissue regeneration or RNA-mediated memory transfer. Specifically, the model illustrates how intracellular memory components might work alongside synaptic connections to create more resilient and multifaceted memory systems—potentially explaining why planaria can maintain memories after decapitation or why RNA transfer can induce learned behaviors. This computational approach could guide future experimental design in neuroscience by predicting how cellular-level memory mechanisms might interact across different timescales and spatial organizations, ultimately leading to a more nuanced understanding of memory encoding, storage, and retrieval in biological systems.</p>



    <!-- if something breaks later on, add back script section form ref.html -->



  </d-article>
  <d-appendix>

    <d-bibliography src="bibliography.bib"></d-bibliography>



  </d-appendix>

  <d-appendix>
    <h3>Appendix 1</h3>
    <p>This sections details the preliminary experiments conducted to determine the deterioration in NCA image reconstruction quality as channels are privatized. We measured the loss curves for reconstruction of a lizard emoji, alongside the regrowth capabilities of the NCA to damage. For all experiments the training was repeated once on a set seed for each privatization level, the regrowth experiments where repeated one-hundred times with the damage locations being fixed and identical for each privatization level.
    </p>
    <p>For these experiments we tested three different NCA types:</p>
    <ul style="margin-top: 0">
      <li><b>DummyVCA</b>: Where the sensing kernels channel dimension match the unmasked NCA channels. However, any kernel involved in sensing neighbourhoods (such as sobel filters) would receive a dummy vector of all zeros for in lieu of the privatized channels.</li>
      <li><b>MaskedCA</b>: Where the sensing kernels channel dimension match the unmasked NCA channels. However, the channels of the output tensor corresponding to the privatized channels where masked with zeros after the sensing convolution.  </li>
      <li><b>ReducedCA</b>: Where the sensing kernels channel dimension where reduced to not include the privatized channels, and a truncated state excluding the privatized channels is passed to the sensing kernels. The state was later re-expanded with zeros t mathc the unmasked NCA channel dimensions.</li>
    </ul>


    <p> The loss function used for training and measuring the reconstruction was the PixelwiseMSE:</p>

    <d-math style="text-align: center; margin: 2rem 0;">

      PixelWiseMSE = \frac{1}{H \times W \times C} \sum_{i=0}^{H} \sum_{j=0}^{W} \sum_{k=0}^{C} \left( I(i, j, k) - \hat{I}(i, j, k) \right)^2

    </d-math>

    <p>Where <d-math>H,W,C</d-math> are the dimension of the image, <d-math>I</d-math> is the reference image, and <d-math>\hat{I}</d-math> is the final state of the NCA.</p>

    <h2>Preliminary experiment results</h2>

    <p><a href="#figure-interComparison" class="figure-link" data-target="figure-interComparison"></a> shows the loss curves of the three models (left to right) with different levels of privatization (0,4,8,12, top to bottom). For privatization levels 0 and 4 the three models are comparable, while at privatization level 8 the DummyVCA performed considerably worse.Finally, the ReducedCA performed best at privatization level 12. From privatization level 0 to 4 there seems to be no discernible change in the loss curves, afterward however, as more channels get privatized the models struggle to learn. </p>

    <figure style="text-align: center; margin: 4rem 0;" id="figure-interComparison"><img playsinline src="figures/Inter_model_comparison.png";
          style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Comparison of the loss curves of the three models (left to right) with different levels of privatization (0,4,8,12, top to bottom). For privatization levels 0 and 4 the three models are comparable, while at privatization level 8 the DummyVCA performed considerably worse.Finally, the ReducedCA performed best at privatization level 12.</figcaption>
    <p><br></p>
    <p><a href="#figure-loss" class="figure-link" data-target="figure-loss"></a> shows how the reconstruction quality (the mean final loss, on a running average of 10) on the lizard emoji decreases as channels are privatized. The data is noisy, thus no proper comparison can be done between the three models, they can be considered to act the same. </p>

    <figure style="text-align: center; margin: 4rem 0;" id="figure-loss"><img playsinline src="figures/Inter_model_loss_fine.png";
          style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Mean final loss as compared to number of channels privatized for each of the three models. As channels are privatized, it can be seen that the reconstruction quality of the original image (mean final loss) decreases. </figcaption>

    <p><br></p>
    <p><a href="#figure-regrowth" class="figure-link" data-target="figure-regrowth"></a> shows the mean regrowth loss of the three models as they attempt to reconstruct the damaged lizard. As with the mean final loss, regrowth quality decreases as the number of channels are privatized. The data is once again noisy, even more so here. This is most likely due to the asynchronous nature of NCAs.  </p>


    <figure style="text-align: center; margin: 4rem 0;" id="figure-regrowth"><img playsinline src="figures/Regrowth_loss.png";
          style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Mean regrowth loss as compared to number of channels privatized for each of the three models. As channels are privatized, it can be seen that the NCA struggles to regrow back to the original image.</figcaption>

    <p><br></p>
    <p>From the results of the preliminary experiments, we concluded that there is indeed deterioration in the quality of image reconstruction from the NCA as channels are privatized. However, the choice of architecture does not play a big role in the level of performance loss. Thus, we chose to go with the MaskedCA version for channel reduction as it was the easiest to implement. </p>
  </d-appendix>

  <d-appendix>
  <h3>Appendix 2</h3>
    <h1>Mathematical details of the proposed models</h1>
    <p>In this section we define the proposed models with mathematical detail.</p>
    <h2>Cellular automaton framework</h2>
    <p>We formalize our EngramNCA as a grid of cells <d-math>C \in \mathbb{R}^{H \times W \times N}</d-math>, where <d-math>H</d-math> and <d-math>W</d-math> are the grid dimensions, and <d-math>N</d-math> is the total number of channels. Each cell <d-math>c_{i,j}</d-math> at position <d-math>(i,j)</d-math> contains a state vector that is partitioned into three components:
</p>
<d-math>c_{i,j} = [v_{i,j}, h_{i,j}, g_{i,j}]</d-math>
    <p><br></p>
<p>
where <d-math>v_{i,j} \in \mathbb{R}^4</d-math> represents the visible RGB-<d-math>\alpha</d-math> channels, <d-math>h_{i,j} \in \mathbb{R}^{n_h}</d-math> represents the public hidden channels, and <d-math>g_{i,j} \in \mathbb{R}^{n_g}</d-math> represents the private gene channels. The dimensions satisfy <d-math>4 + n_h + n_g = N</d-math>.</p>


  <h2>GeneCA architecture</h2>

  <p>GeneCA updates the public channels (visible and hidden) while preserving the private gene channels. For each cell <d-math>c_{i,j}</d-math>, the update rule is defined as:</p>
  <d-math style="text-align: center; margin: 2rem 0;">[v_{i,j}^{t+1}, h_{i,j}^{t+1}] = [v_{i,j}^t, h_{i,j}^t] + \phi_\text{GeneCA}(\mathcal{P}(c_{i,j}^t), g_{i,j}^t)</d-math>
  <d-math style="text-align: center; margin: 2rem 0;">g_{i,j}^{t+1} = g_{i,j}^t</d-math>

  <p>where <d-math>\mathcal{P}(c_{i,j}^t)</d-math> represents the perception vector derived from the cell's neighborhood, and <d-math>\phi_\text{GeneCA}</d-math> is a neural network that computes the update. The perception function <d-math>\mathcal{P}</d-math> applies convolution kernels to the grid:</p>

  <d-math style="text-align: center; margin: 2rem 0;">\mathcal{P}(c_{i,j}^t) = [\text{Identity}(c_{i,j}^t), \text{Sobel}_x(c_{i,j}^t), \text{Sobel}_y(c_{i,j}^t), \text{Laplacian}(c_{i,j}^t)]</d-math>

  <p>where Identity, Sobel<d-math>_x</d-math>, Sobel<d-math>_y</d-math>, and Laplacian are convolution filters applied only to the visible and hidden channels. The neural network <d-math>\phi_\text{GeneCA}</d-math> is structured as:</p>

  <d-math style="text-align: center; margin: 2rem 0;">\phi_\text{GeneCA}(\mathcal{P}, g) = (W_2 \cdot \text{ReLU}(W_1 \cdot [\mathcal{P}, g] + b_1)) \cdot u_m \cdot l_m</d-math>

 <p>where <d-math>W_1, W_2, b_1</d-math> are learnable parameters and <d-math>u_m, l_m</d-math> are the asynchronous update mask and cell living mask respectively. </p>

  <h2>GenePropCA architecture</h2>

  <p>The GenePropCA updates only the gene channels while preserving the public channels:</p>

  <d-math style="text-align: center; margin: 2rem 0;">[v_{i,j}^{t+1}, h_{i,j}^{t+1}] = [v_{i,j}^t, h_{i,j}^t]</d-math>
  <d-math style="text-align: center; margin: 2rem 0;">g_{i,j}^{t+1} = g_{i,j}^t + \psi_\text{GenePropCA}(\mathcal{P}(c_{i,j}^t), g_{i,j}^t)</d-math>

  <p>where <d-math>\psi_\text{GenePropCA}</d-math> is a neural network with a similar architecture to <d-math>\phi_\text{GeneCA}</d-math> but outputs updates for gene channels only:</p>

  <d-math style="text-align: center; margin: 2rem 0;">\psi_\text{GenePropCA}(\mathcal{P}, g) = (V_2 \cdot \text{ReLU}(V_1 \cdot [\mathcal{P}, g] + d_1)) \cdot u_m \cdot l_m</d-math>

  <p>where <d-math>V_1, V_2, d_1</d-math> are learnable parameters and <d-math>u_m, l_m</d-math> are the asynchronous update mask and cell living mask respectively.</p>

  <h2>EngramNCA ensemble</h2>

  <p>The EngramNCA ensemble combines both models in sequence. For a single update step:</p>

  <d-math style="text-align: center; margin: 2rem 0;">c_{i,j}^{t+\frac{1}{2}} = [v_{i,j}^t + \Delta v_{i,j}^t, h_{i,j}^t + \Delta h_{i,j}^t, g_{i,j}^t]</d-math>

  <p>where <d-math>[\Delta v_{i,j}^t, \Delta h_{i,j}^t] = \phi_\text{GeneCA}(\mathcal{P}(c_{i,j}^t), g_{i,j}^t)</d-math>, followed by:</p>

  <d-math style="text-align: center; margin: 2rem 0;">c_{i,j}^{t+1} = [v_{i,j}^{t+\frac{1}{2}}, h_{i,j}^{t+\frac{1}{2}}, g_{i,j}^t + \Delta g_{i,j}^t]</d-math>

  <p>where <d-math>\Delta g_{i,j}^t = \psi_\text{GenePropCA}(\mathcal{P}(c_{i,j}^{t+\frac{1}{2}}), g_{i,j}^t)</d-math>.</p>

  <h2>Training procedure</h2>

  <p>The GeneCA is trained first with frozen gene channels. For each training iteration, we:</p>

  <p>1. Sample a batch of <d-math>B</d-math> cells from pools corresponding to <d-math>K</d-math> different primitive morphologies
2. Initialize the gene channels of each seed cell with a unique binary encoding <d-math>E_k \in \{0,1\}^{n_g}</d-math> for primitive <d-math>k</d-math>
3. Run the GeneCA for <d-math>T</d-math> steps to grow the morphologies
4. Compute the loss using pixelwise MSE between the final visible channels and target images:</p>

  <d-math style="text-align: center; margin: 2rem 0;">\mathcal{L}_\text{GeneCA} = \frac{1}{BHW} \sum_{b=1}^B \sum_{i=1}^H \sum_{j=1}^W ||v_{i,j}^T - \hat{v}_{i,j}||_2^2</d-math>

  <p>After training GeneCA, its weights are frozen, and GenePropCA is trained to propagate and modify gene information to grow complex morphologies. The same loss function is used, but with target images representing complete morphologies rather than primitives.</p>
</d-appendix>

  <d-appendix>
<h3>Acknowledgement</h3>
  <p>This work was partially supported by The Digital Society
strategic initiative at Øsftold University College.</p>
  </d-appendix>

  <distill-appendix>
  <p>BibTeX Citation</p>
  <pre class="citation">
  @article{Guichard2025EngramNCA},
  title = {EngramNCA: a Neural Cellular Automaton Model of Molecular Memory Transfer},
  author = {Guichard, Etienne and Reimers, Felix and Kvalsund, Mia-Katrin and Lepper{\o}d, Mikkel and Nichele, Stefano},
  journal = {Github Preprint},
  year = {2025},
  url = { https://etimush.github.io/EngramNCA/}
  }</pre>
  </distill-appendix>

<script src="./figs.js"></script>
</body>
