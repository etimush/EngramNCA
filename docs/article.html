<d-article class="center">


    <a class="marker" href="#section-1" id="section-1"></a>
    <h2>Introduction</h2>
%% contents.html
    <p>The currently most accepted theory of memory in biological and artificial brains is the synapses dogma <d-cite  key="mayford2012synapses"></d-cite>, that is,
        the place where information is stored is at synapses.  Therefore, it is believed that the storage of memories
        happens through changes in synaptic strengths <d-cite  key="cajal1894fine"></d-cite>. This view is challenged by emerging evidence that memory is also
        present privately within cells <d-cite  key="abraham2019plasticity"></d-cite>, and synapses are merely a visible reverberation of such private memories  <d-cite  key="gold2021central"></d-cite>.
        Compelling examples are the evidence of memory transfer via injection of RNA extracted from trained Aplysia into
        untrained animals <d-cite  key="Bedecarrats2018"></d-cite>, the memory transfer via a soup of trained planaria fed to untrained organisms <d-cite  key="mcconnell1967modern"></d-cite>, and the decapitation
        of planaria that retained long-term memories after head regeneration <d-cite  key="shomrat2013automated"></d-cite>.In this work, we propose a Neural Cellular Automaton (NCA) <d-cite  key="mordvintsev2020growing"></d-cite> model that allows for private memory storage within cells and memory transfer across cells. We extend the NCA in two ways:


    </p>

    <ul style="margin-top: 0">
<li>Each cell has a publicly visible state (comprised by a certain number of public CA channels) that can be accessed by neighboring cells and used as available information for computing cell state updates. This is akin to information transmitted through synapses to neighboring cells.</li>
<li>Each cell has a private memory (comprised by a certain number of private CA channels) that is visible only to the cell itself. This represents some sort of internal state stored more permanently in a cell, that can be possibly transmitted or made available to other cells in a manner akin to RNA transfer (or other plausible molecular transfer mechanisms).</li>
</ul>

    <p>When CA cells update their state, their internal neural network (a homogeneous neural network with identical
        weights for all cells) acts upon the visible channels in the neighborhood, in addition to the cell’s own private
        memory. The result is the interplay of the visible component and the (private) memory stored within the cell.
    </p>
    <p>As such, a focus is to train the NCA to utilize its cells internal memory to full capacity, since it is not directly accessible by other cells.
        Therefore, it has to learn to produce a reverberation of it through its visible channels in order to carry out
        the collective computation in coordination with the neighbors.
    </p>

    <p>This coordination is achieved by first training an NCA to grow from a seed cell to a set of primitive morphologies.
        The only cell initially containing the genetic information (private memory) representing the target morphology is the seed cell itself.
        Each morphology is encoded by a different private representation. Therefore, this NCA has to learn to achieve the global task only through its visible channels.
        The neural network weights of this first NCA are then frozen and do not change. We name this first neural network GeneCA.
    </p>

    <p>Subsequently, another NCA is trained in addition to the previous, which does not manipulate and change the visible
        information of cells, but can only change their private genetic memory, i.e., a set of private channels. As such,
        it has to learn a mechanism to regulate the private information such that the previously learned primitive morphologies
        (or their combination) can be utilized and activated at the right time and in the right place. We name this second neural network GenePropCA, short for GenePropagationCA.</p>

    <p>The GenePropCA mechanism is an abstraction for mRNA transmission between cells, which provides a form of functionality transfer.
        The transmitted functionality is stored in the cell’s internal memory and, in turn, affects the behavior of the GeneCA (the cell’s visible state). </p>

    <p>Note that in biological systems, the two types of information transfer, i.e., synaptic transfer and mRNA transfer,
        may happen at two different timescales. Typically, spikes through synapses are transmitted faster than mRNA transfers.
        However, in our framework we have tested with different timescales (basically running the GeneCA faster than the GenePropCA,
        or vice versa) without affecting the functionality. Overall, the system learns to adjust the rate of updates from one of the two NCA to solve the task at hand.

    </p>

    <p>We test the proposed NCAs on different morphogenetic tasks, including the growth of simple yet stable primitives,
        out-of-distribution mixtures of primitives, more complex morphologies obtained by the combination of basic primitives,
        and moving primitives such as Lenia gliders. </p>




    <a class="marker" href="#section-2" id="section-2"></a>
    <h2>Model(s)</h2>
    <p>In this section , we introduce the changes to the overall architecture from <d-cite  key="mordvintsev2020growing"></d-cite>,
        and detail the implementation of the two new models (GeneCA snd GenePropCA, respectively), including illustrations of their specific architecture and
        how they interact with each-other.
    </p>

    <p>Taking inspiration from RNA memory transfer observed Planarians and Aplysia, we augment the NCA hidden state with a "private tape".
    Instead of extending the classic NCA model by appending the tape to the hidden states, we choose to sacrifice hidden states by privatizing them, this ensures that any
    improvements seen are not due to an increase in model size (please see Appendix 1 for masking of hidden channels to investigate task deterioration with less available channels). The hypothesis here is that the private tape augmentation can be exploited to encode different modalities of behaviour,
    such as growing different shapes or representing different computations. An illustration is provided in <a href="#figure-augment" class="figure-link" data-target="figure-augment"></a>, where the channels of the cell are represented, including the RGB
    channels, the alpha channel, three additional channels, plus three gene channels (G1,G2, and G3) representing the private tape.

    <figure style="text-align: center; margin: 4rem 0;" id="figure-augment"><img playsinline src="figures/gene.drawio.svg";
          style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>NCA augmentation through gene embedding channels, where the channels of the cell are represented, including the RGB channels, the alpha channel, three additional channels, plus three gene channels (G1,G2, and G3) representing the private tape.</figcaption>
    <p><br></p>
    <p>We chose to encode different "primitives" in the tape through binary representation. These primitives can consist of simple shapes such as convex polygons or
    more complex, convex, compound shapes such as body segments of a lizard emoji. Examples of encodings are represented in <a href="#figure-embed" class="figure-link" data-target="figure-embed"></a>  and <a href="#figure-embedliz" class="figure-link" data-target="figure-embedliz"></a>, where three basic geometric morphologies and lizard parts are given, respectively.</p>
    <figure style="text-align: center; margin: 4rem 0;" id="figure-embed" ><img playsinline src="figures/embedding.drawio.svg";
          style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption> Binary embedding of geometric morphologies and their respective encoding.</figcaption>
     <p><br></p>      
    <p>The tape length has to be chosen such that <d-math>2^{gene\_channels}   </d-math> is greater or equal to the number of primitives. This ensures that,due to the binary representation, there are enough
    distinct binary encodings for each primitive. However, due to reasons that will be discussed later, it is often preferable to have a buffer of genes that are not used
    in the binary encoding. There is a delicate balance between the number of gene bits and shared hidden channels that needs to be reached as privatisation of channels
    ensures a performance penalty (see Appendix 1 for details). </p>

    <figure style="text-align: center; margin: 2rem 0;" id="figure-embedliz"><img playsinline src="figures/LizEmbeddings.drawio.svg";
          style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption> Binary embedding of lizard body sections and their respective encodings. </figcaption>



    <a class="marker" href="#section-2.1" id="section-2.1"></a>
    <h3>GeneCA</h3>


    <p>The first model (<a href="#figure-div" class="figure-link" data-target="figure-div"></a>), which we  name GeneCA, is tasked with learning the primitive embedding. It takes
    inspiration form the original NCA <d-cite key="mordvintsev2020growing"></d-cite> and is extended to also include a laplacian convolution filter as found in <d-cite key="mordvintsev2022growing"></d-cite>. Notably,
        the parameters only produce a partial cell-state update-vector that comprises all non-gene channels. The gene channels are cloned and appended to the update vector after the stochastic
    update step to prevent degradation over time. This leads to no change or propagation of gene channel information throughout the NCA cell. It is worth to note that, since the only
        living cell that is initialized at the beginning of each run is a single seed cell, all cells besides the seed cell have no information in their gene channels (i.e., all zeros).
        This means that the GeneCA learns to grow the primitive morphologies from a seed cell without relying on a mechanism to transmit the gene channel information to other cells.
        Additionally, this signifies that cells do not practically observe the private tape of neighboring cells.</p>

      <figure style="text-align: center; margin: 2rem 0;" id="figure-div">
    <img playsinline src="figures/Gene.drawio.svg" style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" />
    <figcaption>One step of the GeneCA</figcaption>
    </figure>


    <a class="marker" href="#section-2.2" id="section-2.2"></a>
    <h3>GenePropCA</h3>

    <p>The GenePropCA model (<a href="#GeneProp" class="figure-link" data-target="GeneProp"></a>) is tasked with exploiting the gene embedding learned by the GeneCA.
    By conditioning the primitive growth in the GeneCA to a specific embedding, these embeddings now carry latent information about the primitives. We assume that the latent information
    in each embedding can be modified to produce out-of-training behaviour, thus allowing the GenePropCA to both propagate and modify the genes to achieve a desired goal.
    The architecture of the GenePropCA is similar to that of the GeneCA, where the neural network parameters produce a partial cell state update. In this case, only the genes channels are updated. Like in
    the GeneCA, the unmodified cell states are cloned and appended after the asynchronous partial update, leading to the GenePropCA having no influence over non-gene channels. </p>

    <figure style="text-align: center; margin: 2rem 0;" id="GeneProp"><img playsinline src="figures/GeneProp1.drawio.svg"
      style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>One step of the GenePropCA</figcaption>




    <a class="marker" href="#section-2.3" id="section-2.3"></a>
    <h3>Ensemble</h3>

    

    <p>The ensemble model (<a href="#Enseble" class="figure-link" data-target="Enseble"></a>) uses the GeneCA and GenePropCA to produce the final morphology. The GeneCA works without the GenePropCA and will produce the primitives. The
    GenePropCA is dependent on the GeneCA as its parameters are trained to manipulate the GeneCA dynamics. At step N, the state of the CA is passed to the GeneCA, where it only modifies the visible and hidden channels
    to produce an intermediate state, the intermediate step is then passed to the GenePropCA, where only the gene encoding channels are modified to produce step N+1. The idea here is for the
    GenePropCA to learn to exploit the gene embedded dynamics of the GeneCA to produce more complex morphologies than that found in the GeneCA.</p>

    <figure style="text-align: center; margin: 2rem 0;" id="Enseble"><img playsinline src="figures/Enseble.drawio.svg"
      style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>One step of the ensemble, GeneCA + GenePropCA</figcaption>


    <a class="marker" href="#section-3" id="section-3"></a>
    <h2>Hierarchical Growth Task</h2>

    <p>The traditional NCAs presented in <d-cite key="mordvintsev2020growing">"</d-cite>  uses the neural-network
    parameters to encode the desired behaviour. In effect, the neural-network can be seen as the genome for the morphology, where for each distinct morphology a new NCA needs to be trained.
    This makes it particularly difficult to have coexisting morphologies, or even just coexisting dynamics, existing on the same lattice, as the multiple NCAs end up interfering with each-other.</p>

    <p>Our model presents a possible solution to this problem by tying the morphological result to an unchanging seed cell. In this way, we hope that
    the NCA learns general growing dynamics that are necessary for any morphology, alongside encoding-specific dynamics for the details of the morphology.  </p>

    <a class="marker" href="#section-3.1" id="section-3.1"></a>
    <h3>Growing Coexisting Primitives</h3>

    <p>The first step in the hierarchical growth task was to grow coexisting morphologies. In effect, this means to grow multiple distinct morphologies using the same set of NCA (our GeneCA) parameters. Much like the original growth task as described in <d-cite key="mordvintsev2020growing">"</d-cite>, the
    multiple morphologies should be bounded and stable across time, with their shape unchanging once fully generated.
        We conducted multiple experiments including; many high-complexity primitives (lizard body parts, <a href="#AllPrims" class="figure-link" data-target="AllPrims"></a>, left), fewer medium-complexity primitives (basic polygons, <a href="#AllPrims" class="figure-link" data-target="AllPrims"></a>, middle), and fewer low-complexity shapes (vertical and horizontal lines, <a href="#AllPrims" class="figure-link" data-target="AllPrims"></a>, right). </p>

    <figure style="text-align: center; margin: 2rem 0;" id="AllPrims"><img playsinline src="figures/all_prims_2.drawio.svg"
      style="width:70%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Left: All lizard body parts used in training a GeneCA. Middle: All polygons sed in training a GeneCA. Right: Vertical and horizontal lines sed in training a GeneCA.</figcaption>


    <a class="marker" href="#section-3.2" id="section-3.2"></a>
    <h3>Growing Morphologies from Primitives</h3>

    <p>From a trained GeneCA we then trained the GenePropCA to exploit the latent-space embeddings that the genes now represent. The three different
        GeneCA mentioned previously where used to test the GenePropCAs capabilities under different circumstances. A high primitive count, low combinatorial problem in growing the lizard (<a href="#LizFract" class="figure-link" data-target="LizFract"></a>, left), where there is only one valid combination. A low primitive count, high combinatorial
    problem in growing a fractal-like shape (<a href="#LizFract" class="figure-link" data-target="LizFract"></a>, right) from vertical and horizontal lines. Finally, a combination of the two, by growing a lizard from basic polygons.</p>

    <figure style="text-align: center; margin: 2rem 0;" id="LizFract"><img playsinline src="figures/liz_fract.drawio.svg"
      style="width:70%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Left: Full Lizard morphology used in training the GenePropCA. Right: Fractal-like morphology used in training the GenePropCA .</figcaption>



    <a class="marker" href="#section-3.3" id="section-3.3"></a>
    <h3>Growing Coexisting Morphologies</h3>

    <p>For final step in the hierarchy, we chose to explore  growing multiple morphologies from the same GeneCA and GenePropCA. This was accomplished by extending the model one hierarchy up, and imbuing the GenePropCA  with its own meta-genes, that it could see, but  neither it nor the GeneCA could modify, and using those meta-genes to encode for entire morphologies.</p>



    <a class="marker" href="#section-4" id="section-4"></a>
    <h2>Training Procedure</h2>
    <p>In this section we provide a  description of the training procedure,  including two distinct training phases, a special pooling method to train multiple primitives at one, and how the GeneCA weights are frozen when training the GenePropCA.</p>

    <p> The loss function used for training on all the images is the Pixelwise-MSE:</p>

    <d-math style="text-align: center; margin: 2rem 0;">

      PixelWiseMSE = \frac{1}{H \times W \times C} \sum_{i=0}^{H} \sum_{j=0}^{W} \sum_{k=0  }^{C} \left( I(i, j, k) - \hat{I}(i, j, k) \right)^2

    </d-math>

    <p>Where <d-math>H,W,C</d-math> are the dimension of the image, <d-math>I</d-math> is the reference image, and <d-math>\hat{I}</d-math> is the final state of the NCA.</p>

    <a class="marker" href="#section-4.1" id="section-4.1"></a>
    <h3>GeneCA Training</h3>
    <p>GeneCA training is similar to the pool-training procedure presented in <d-cite key="mordvintsev2020growing"></d-cite>. However, to enable the gene encoding of multiple primitives,
    each gene-primitive pair is given its own pool to sample from and update. Additionally, the target image becomes a target batch consisting of n-repetitions of each image,
    where n is a factor of the batch size. This is done so that multiple images per batch can be considered in the loss. It is important to keep the batch size as a multiple of the number of primitives to avoid training bias towards one primitive. <a href="#multiTraining" class="figure-link" data-target="multiTraining"></a> illustrates the training procedure for batch-multi-image training under the GeneCA scheme.</p>

    <figure style="text-align: center; margin: 2rem 0;" id="multiTraining"><img playsinline src="figures/Training.drawio.svg"
      style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Training loop for multi-image batch training</figcaption>

    <a class="marker" href="#section-4.2" id="section-4.2"></a>
    <h3>GenePropCA Training</h3>
    <p>GenePropCA training uses the same batch training technique as the GeneCA. We typically only train a single morphology, however multiple morphologies can be trained by
    sacrificing more channels to act as "meta genes". These meta genes are unaffected by both the GeneCA and GenePropCA. During the training of the GenePropCA the GeneCA weights are frozen,
    though their gradient contribution during the growth process is still used when backpropagating the loss to the GenePropCA. This ensures the GenePropCA's dynamics are
        conditioned on those of the GeneCA. <a href="#dualtraining" class="figure-link" data-target="dualtraining"></a> shows the GenePropCA training with GeneCA frozen weights.</p>
     <figure style="text-align: center; margin: 2rem 0;" id="dualtraining"><img playsinline src="figures/training_prop.drawio.svg"
      style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Training loop for GenePropCA. The GeneCA weights are frozen, yet still contribute to the gradient computations, making the GenePropCAs behaviour dependent on the GeneCA.</figcaption>
    <a class="marker" href="#section-5" id="section-5"></a>
    <h2>Results</h2>
    <p>The model was tested with configuration. Below are the results of those experiments. Generally, the NCA has a size of 30 x 30, there are 16 channels in total of which the first four are the alpha value and the three color channels. Of the remaining 12 hidden channels, eight channels were privatized, i.e. could be read but not be altered by the GeneCA. </p>

    <a class="marker" href="#section-5.1" id="section-5.1"></a>
    <h3>Growing Coexisting Primitives </h3>

    <p>Three primitives were chosen as target shapes: A blue square, a green circle and a red triangle. Those primitives have a corresponding one-hot encoding in the private tape. The GeneCA was trained to update the public channels of the CA such that the right primitive is formed around the seed cell. It is important to note that there is no gene propagation at this point, only the update of the public channels that the GeneCA calculates based on the available private and public channels. </p>
    <p>During test time, cells of the CA are picked as seed cells, and their private tape is altered. </p>

    <p>In the top of <a href="#growing-prims" class="figure-link" data-target="growing-prims"></a> we show how the binary encodings of the three primitives are assigned to three different cells in the CA, with the distance between them being great enough to avoid interactions between cells belonging to different primitives. Starting from the seed cell, the shapes and their color form over a number of update steps. Afterwards, they remain stable. </p>
    <figure style="text-align: center; margin: 2rem 0;" id="growing-prims"><video loop autoplay playsinline muted width="640px"; src="figures/Primitives.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing simple primitives.</figcaption>
    <p></p>
    <p> <a href="#individuality-demo" class="figure-link" data-target="individuality-demo"></a> shows what happens if seed cells are placed in such proximity to each other that the resulting primitives would normally overlap.
        As can be seen, the shapes remain largely distinct. Especially shapes of the same kind have neither overlap nor mixing and instead a border
        can be visually seen. Circles placed in proximity to each other can for example be seen to form a comb-like structure (top of <a href="#individuality-demo" class="figure-link" data-target="individuality-demo"></a>).
        If shapes of different kinds meet, the distinction is not always as clear and some interactions between different primitives can lead to a
        mixing of colors, as can be seen in the bottom of <a href="#individuality-demo" class="figure-link" data-target="individuality-demo"></a>. Still, a distinction can be made and no primitive takes over another primitive.
        This happens without such cases occurring during training. </p>
    <figure style="text-align: center; margin: 2rem 0;" id="individuality-demo"><video loop autoplay playsinline muted width="640px"; src="figures/Individuals.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Untrained behaviour: primitives displaying strong individuality.</figcaption>
    <p></p>
    <p>Only the three one-hot encodings were used during training, but it is possible to deviate from this during test time and to use different binary arrays as the private encodings of the seed cell.
        This essentially means that there is a mixture of genes. As can be seen in <a href="#primitive-mixing" class="figure-link" data-target="primitive-mixing"></a>, this leads to the growth of corresponding mixed forms. It can be seen that the shape of those forms is a
        distorted overlap of the primitives while the color ranges from the pure color of the primitives to the mix of the two colors. The primitives dominate the developing form in those areas where
        the other primitive is not growing, hence the combination of circle and square leads to most mixing. After a developmental period, the forms remain stable. This stability remains for any form of
        encoding mixing and seems to be bound by the maximum size of the primitives. </p>

    <figure style="text-align: center; margin: 2rem 0;" id="primitive-mixing"><video loop autoplay playsinline muted width="640px"; src="figures/Mixed.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Untrained behaviour: out-of-training generative capabilities from mixing genes.</figcaption>
    <p></p>
    <p>The experiments were repeated with body parts of the lizard image as primitives as can be seen in <a href="#body-part-prims" class="figure-link" data-target="body-part-prims"></a>. As those were more than three parts, the encoding is not one-hot anymore. As before, placing a seed cell with the corresponding encoding
        leads to the growth and stable persistence of primitives, even though those have more complex shapes and colorings. </p>

    <figure style="text-align: center; margin: 2rem 0;" id="body-part-prims"><video loop autoplay playsinline muted width="640px"; src="figures/body_parts.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Lizard body parts primitives.</figcaption>
    <p></p>
    <p>Lastly, very simple unicolor vertical and horizontal lines were used as primitive as is depicted in <a href="#line-prims" class="figure-link" data-target="line-prims"></a>. This is the setup for later experiments. </p>

     <figure style="text-align: center; margin: 2rem 0;" id="line-prims"><video loop autoplay playsinline muted width="640px"; src="figures/horiz_vert.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Horizontal and vertical line primitives.</figcaption>




    <a class="marker" href="#section-5.2" id="section-5.2"></a>
    <h3>Growing Morphologies from Primitives </h3>

    <p>At the next experimental step, the GenePropCA was included. The attempt was to grow whole morphologies, while the GeneCA weights where frozen on growing primitives.</p>
    <p>In the lizard example, the GenePropCA was trained as described above with the initial seed cell containing the gene encoding for the torso primitive and the GeneCA being trained
        on primitive body parts of the whole lizard (legs, head, torso, tail). As can be seen in <a href="#liz-from-parts" class="figure-link" data-target="liz-from-parts"></a>, the torso of the lizard is grown first, but the CA then continues to grow the limbs, tail and head. Deactivating
        the GenePropCA after the lizard is finished growing does not lead to a collapse, rather the lizard maintains its shape under the control of the GeneCA. </p>
    <figure style="text-align: center; margin: 2rem 0;" id="liz-from-parts"><video loop autoplay playsinline muted width="640px"; src="figures/Growing_from_torso.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing the lizard morphology from the torso.</figcaption>
    <p></p>
    <p>The experiment was repeated, this time choosing the circle, square and triangle as primitives and the blue circle as the seed cell during the GenePropCA training. This was successful, as can be seen
        in <a href="#liz-from-shapes" class="figure-link" data-target="liz-from-shapes"></a>. Even if the GeneCA is not trained on all primitives occurring in the final lizard or even on primitives not derived from the target image at all, the GenePropCA
        is able to generalize and facilitate gene propagation that leads to the growth of the lizard, albeit with less quality as in the case described above for <a href="#liz-from-parts" class="figure-link" data-target="liz-from-parts"></a>. <a href="#liz-diff-start" class="figure-link" data-target="liz-diff-start"></a>
        shows that the choice of the seed cell does indeed matter, as the lizard will only grow successfully if the exact same seed as in the training of the GenePropCA is used.  </p>
    <p>Further experiments showed that different seeds, which were not used as primitives during the training of the GeneCA, can be used to train the GenePropCA to grow a lizard.  </p>
    <figure style="text-align: center; margin: 2rem 0;" id="liz-from-shapes"><video loop autoplay playsinline muted width="640px"; src="figures/GrowingLizardFast.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing the lizard from basic polygon morphologies.</figcaption>
    <figure style="text-align: center; margin: 2rem 0;" id="liz-diff-start"><video loop autoplay playsinline muted width="640px"; src="figures/GrowingMorpho_multi.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing the lizard from basic polygon morphologies.The lizard will not grow from a primitive it was not trained to grow from.</figcaption>
    <p></p>
    <p><a href="#grow-frac" class="figure-link" data-target="grow-frac"></a> depicts an experiment in which the simple primitives of unicolor vertical and horizontal lines are combined into a fractal-like shape with satisfying performance. This shows that the model can combine simple and few primitives into more complex
        forms consisting of many primitives in addition to combining complex and many primitives into less complex (complexity in the sense of the combination of primitives) forms consisting of few primitives, as was done before with the lizard. </p>

    <figure style="text-align: center; margin: 2rem 0;" id="grow-frac"><video loop autoplay playsinline muted width="640px"; src="figures/fract.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing a fractal-like shape from simple vertical and horizontal primitives.</figcaption>

    <a class="marker" href="#section-5.3" id="section-5.3"></a>
    <h3>Growing Coexisting Morphologies from Primitives </h3>

    <p>The final experiment in growing morphologies was to test whether the GenePropCA could additionally grow multiple morphologies. This was done by adding an extra channel as a meta-gene, that neither the GeneCA nor GenePropCA could modify and training the GenePropCA to grow separate morphologies depending on the meta-gene encoding and the starting seed cell encoding.</p>
    <p><a href="#2-morph" class="figure-link" data-target="2-morph"></a> shows the GenePropCA growing both a lizard morphology and a butterfly by exploiting the same GeneCA gene encodings. The overall quality of reproduction of the lizard has diminished, whilst the butterfly, a much simpler morphology, was reproduced better.</p>
      <figure style="text-align: center; margin: 2rem 0;" id="2-morph"><video loop autoplay playsinline muted width="640px"; src="figures/multi_morpho.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing both a lizard and a butterfly with the same GeneCA and GenePropCA. The quality of reproduction is reduced.</figcaption>

    <a class="marker" href="#section-5.4" id="section-5.4"></a>
    <h3>Moving Primitives </h3>

    <p>In contrast to the relatively simple task of growing morphologies, we wanted to test if the GenePropCA could exploit the embedding and learn the dynamics of
    a complex moving system. For this we chose to replicate the dynamics of a Lenia  <d-cite  key="Lenia2019"></d-cite> glider. Lenia itself is a form of continuous CA that can exhibit remarkable complexity.
    We chose a glider (<a href="#originalLenia" class="figure-link" data-target="originalLenia"></a>)  whose dynamics where non-trivial, where learning to replicate it
    would take more than simply memorising a simple translation in space. The GeneCA was trained on the first frame of the Lenia video. The GenePropCA was trained on a
    quasi-curriculum-style learning, where at certain checkpoints additional frames of the video are inserted into the training set until the five-hundreds frame. It is always trained from the first frame
    to the last frame of the training set in order, and loss was accumulated across all frames before backpropagation. The frame-by-frame loss accumulation is important here
    since -unlike growing morphologies- the time evolution of the NCA from state to state is important. As a comparison a standard NCA was trained using the same method, the parameter count
    of the standard NCA was selected such that it corresponds to the sum of total parameters between the GeneCA and the GenePropCA.</p>

    <figure style="text-align: center; margin: 2rem 0;" id="originalLenia"><img playsinline src="figures/original_lenia.gif"
      style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Original Lenia video.</figcaption>
    <p></p>

    <p><a href="#standardNCA" class="figure-link" data-target="standardNCA"></a> shows the result of training a standard NCA on five-hundred frames of the Lenia video. As can be seen, the standard NCA somewhat replicates the dynamics until a certain point, where the simulation falls apart. Possibly due to the NCA only learning to replicate the exact frames it saw and not learning the dynamics.</p>

    <figure style="text-align: center; margin: 2rem 0;" id="standardNCA"><img playsinline src="figures/standard_nca.gif"
      style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Standard NCA trained to replicate the video.</figcaption>
    <p></p>
    <p>(<a href="#movingGene" class="figure-link" data-target="movingGene"></a>) shows the result of training the GeneCA and GenePropCA on five-hundred frames of the Lenia video. As can be seen, our method yields visually closer results to the Lenia video. Additionally, the morphology is stable past the five-hundred frame mark, exhibiting signs of having learned more general dynamics that are stable in time.  Though not a perfect replication of the Lenia glider, the results are decent.</p>

    <figure style="text-align: center; margin: 2rem 0;" id="movingGene"><img playsinline src="figures/Gene_ca_moving.gif"
      style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Our method trained to replicate the video.</figcaption>

    <a class="marker" href="#section-6" id="section-6"></a>
    <h2>Related NCA Work</h2>

    <p>Neural cellular automata (NCAs) merge the classical framework of cellular automata with modern deep learning by replacing hand-crafted update rules with neural networks that are optimized via gradient-based methods. Earlier studies in cellular automata (e.g., <d-cite  key="Wolfram2002"></d-cite>) established that simple local rules can lead to complex emergent behavior. Building on these ideas, <d-cite  key="mordvintsev2020growing"></d-cite> introduced the “Growing Neural Cellular Automata” model, which trains a convolutional network with gradient-based learning to iteratively update a grid so that, starting from a single seed, complex images emerge and can regenerate after damage.</p>
    <p>Seminal work by <d-cite  key="miller2004evolving"></d-cite> explored evolving self-repairing, self-regulating cellular automata to produce the “French flag” pattern, demonstrating how evolutionary algorithms can discover diverse rule sets for complex morphogenesis. <d-cite  key="nichele2017neat"></d-cite> extended morphogenetic CAs with neuro-evolution of neural networks as CA rules. <d-cite  key="pontescritical"></d-cite> showed a NCA evolved to criticality. This was further studied by <d-cite  key="Guichard2024"></d-cite>. <d-cite  key="kvalsund2024sensor"></d-cite> discussed NCA a model for a distributed neocortex. </p>

    <p>A range of extensions have broadened the capabilities of NCAs.<d-cite  key="randazzo2020self"></d-cite> explored self-classification tasks. <d-cite  key="hernandez2021neural"></d-cite> presented NCA Manifold, creating embedding spaces of different morphogenetic processes. <d-cite  key="tesfaldet2022attention"></d-cite> developed an attention-based NCA that integrates self-attention mechanisms into the update process, allowing each cell to dynamically focus on relevant features in its local neighborhood and capture longer-range dependencies. <d-cite  key="grasso2022empowered"></d-cite> proposed Empowered Neural Cellular Automata, incorporating an information-theoretic objective (empowerment) to promote robust, coordinated behaviors. <d-cite  key="palm2022variational"></d-cite> proposed Variational Neural Cellular Automata, a probabilistic generative model that captures diverse emergent dynamics through variational inference. <d-cite  key="mordvintsev2022growing"></d-cite> proposed an isotropic version of NCAs, while <d-cite  key="pande2023hierarchical"></d-cite> presented Hierarchical NCA to model emergent behaviors at different scales.</p>

    <p>Extensions in application domains further illustrate the versatility of the NCA framework. <d-cite  key="variengien2021towards"></d-cite> applied NCAs to evolve controllers for a cart-pole system. <d-cite  key="horibe2022severe"></d-cite> demonstrated the use of NCAs for regenerating soft robot morphologies, showcasing their potential for self-repair akin to biological regeneration. <d-cite  key="najarro2022hypernca"></d-cite> studied a hypernetwork approach, named HyperNCA, that grows artificial neural networks with a developmental process. More recently, <d-cite  key="Reimers2023"></d-cite> introduced a pathfinding NCA with local self-attention, training automata to collectively explore environments and locate energy sources. <d-cite  key="randazzo2024simulating"></d-cite> exploited an NCA as an evolvable plant biome. Very recently, Differentiable Logic Cellular Automata by <d-cite  key="Pietro-Miotti-Eyvind-Niklasson-Ettore-Randazzo-Alexander-Mordvintsev2025-jb"></d-cite> integrates differentiable logic gates with traditional neural cellular automata to achieve discrete, interpretable update rules while maintaining the benefits of gradient-based training.</p>

    <p>One work that greatly inspired us is <d-cite  key="Pappadopoulos2023"></d-cite>, where the incorporation of additional channels to encode for different morphologies is discussed. More broadly, we were greatly inspired by <d-cite  key="MitchellCheney2024"></d-cite> and <d-cite  key="HartlLevin2024"></d-cite>, arguing that living systems encode robust, adaptable generative models that guide development and regeneration. Such works emphasize that biological lineages accumulate “memory engrams”—latent representations that enable organisms to reliably rebuild form and function despite perturbations. This concept is central in our idea of EngramNCA, where the model leverages dual-channel memory (public and private states) to simulate the distributed storage and transfer of memory observed in biological systems.

</p>


    <a class="marker" href="#section-7" id="section-7"></a>
    <h2>Summary and Discussion</h2>
    <p>The prevailing paradigm in neuroscience has long held that memory is predominantly stored and transmitted through synaptic plasticity—the so‐called “synaptic dogma” <d-cite  key="Kandel2001"></d-cite>. This view posits that modifications in synaptic strength are the primary means by which information is encoded in neural circuits. However, a growing body of experimental evidence suggests that memory storage may also involve intracellular processes and molecular mechanisms. For instance, studies in Aplysia have demonstrated that injection of RNA extracted from trained animals into naïve counterparts can induce memory‐like changes, implying that molecular substrates may contribute to memory formation beyond traditional synaptic modifications <d-cite  key="Bedecarrats2018"></d-cite>. Similarly, research on planaria has shown that decapitated individuals can retain learned behaviors after head regeneration, further suggesting that memory may reside in non‐synaptic, cellular compartments (<d-cite  key="McConnell1962"></d-cite>; <d-cite  key="Shomrat2013"></d-cite>).


These findings have significant implications for both biological and computational models of memory. Whereas classical models emphasize network-level interactions and synaptic weight adjustments, recent work has increasingly focused on the roles of gene expression and intracellular signaling cascades in long-term memory storage (<d-cite  key="Kandel2014"></d-cite>). Insights from developmental biology also support this broader perspective; gene regulatory networks, for example, orchestrate complex morphogenetic processes (<d-cite  key="Davidson2006"></d-cite>), underscoring the potential for multi-timescale information transfer that integrates fast synaptic signaling with slower, gene-mediated processes.</p>

    <p>Inspired by these biological insights, emerging computational frameworks—such as the one proposed here and named EngramNCA—are exploring dual modes of information storage. In these models, the system is endowed with a bifurcated state representation: a publicly accessible channel that mirrors synaptic activity and a private channel that represents intracellular memory. This dual-channel approach reflects the biological separation between immediate synaptic signaling and slower molecular memory transfer, offering a more nuanced basis for capturing complex developmental and memory dynamics.

In summary, while the synaptic model of memory has dominated for decades, converging evidence from RNA-mediated experiments in Aplysia and memory transfer studies in planaria underscores the importance of intracellular and molecular contributions to memory storage. Integrating these biological principles into computational models may ultimately pave the way for more robust and adaptable systems.</p>





    <!-- if something breaks later on, add back script section form ref.html -->



  </d-article>