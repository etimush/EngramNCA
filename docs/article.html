<d-article class="center">


    <a class="marker" href="#section-1" id="section-1"></a>
    <h2>Introduction</h2>
%% contents.html
    <p>The currently most accepted theory of memory in biological and artificial brains is the synapses dogma, that is,
        the place where information is stored is at synapses.  Therefore, it is believed that the storage of memories
        happens through changes in synaptic strengths. This view is challenged by emerging evidence that memory is also
        present privately within cells, and synapses are merely a visible reverberation of such private memories.
        Compelling examples are the evidence of memory transfer via injection of RNA extracted from trained Aplysia into
        untrained animals, the memory transfer via a soup of trained planaria fed to untrained organisms, and the decapitation
        of planaria that retained long-term memories after head regeneration. </p>

    <ul>In this work, we propose a Neural Cellular Automaton (NCA) model that allows for private memory storage within cells and molecular transfer across cells. We extend the NCA in two ways:
<li>Each cell has a publicly visible state (comprised by a certain number of public CA channels) that can be accessed by neighboring cells and used as available information for computing cell state updates. This is akin to information transmitted through synapses to neighboring cells.</li>
<li>Each cell has a private memory (comprised by a certain number of private CA channels) that is visible only to the cell itself. This represents some sort of internal functionality stored more permanently in a cell, that can be possibly transmitted or made available to other cells in a manner akin to RNA transfer (or other plausible molecular transfer mechanisms).</li>
</ul>

    <p>When CA cells update their state, their internal neural network (a homogeneous neural network with identical
        weights for all cells) acts upon the visible channels in the neighborhood, in addition to the cell’s own private
        memory. The result is the interplay of the visible component and the (private) memory stored within the cell.
    </p>
    <p>As such, the NCA has to learn to use its internal memory, since it is not directly accessible to other cells.
        Therefore, it has to learn to produce a reverberation of it through its visible channels in order to carry out
        the collective computation in coordination with the neighbors.
    </p>

    <p>This coordination is achieved by first training an NCA to grow from a seed cell to a set of primitive morphologies.
        The only cell initially containing the genetic information (private memory) representing the target morphology is the seed cell itself.
        Each morphology is encoded by a different private representation. Therefore, this NCA has to learn to achieve the global task only through its visible channels.
        The neural network weights of this first NCA are then frozen and do not change. We name this first neural network GeneCA.
    </p>

    <p>Subsequently, another NCA is trained in addition to the previous, which does not manipulate and change the visible
        information of cells, bun can only change their private genetic memory, i.e., a set of private channels. As such,
        it has to learn a mechanism to regulate the private information such that the previously learned primitive morphologies
        (or their combination) can be utilized and activated at the right time and in the right place. We name this second neural network GenePropCA.</p>

    <p>The GenePropCA mechanism is an abstraction for mRNA transmission between cells, which provides a form of functionality transfer.
        The transmitted functionality is stored in the cell’s internal memory and, in turn, affects the behavior of the GeneCA (the cell’s visible state). </p>

    <p>Note that in biological systems, the two types of information transfer, i.e., synaptic transfer and mRNA transfer,
        may happen at two different timescales. Typically, spikes through synapses are transmitted faster than mRNA transfers.
        However, in our framework we have tested with different timescales (basically running the GeneCA faster than the GenePropCA,
        or vice versa) without affecting the functionality. Overall, the system learns to adjust to more often updates from one of the two NCA to solve the task at hand.

    </p>

    <p>We test the proposed NCAs on different morphogenetic tasks, including the growth of simple yet stable primitives,
        out-of-distribution mixtures of primitives, more complex morphologies obtained by the combination of basic primitives,
        and moving primitives such as Lenia gliders. </p>




    <a class="marker" href="#section-2" id="section-2"></a>
    <h2>Model(s)</h2>
    <p>Description of both models, including illustrations of their architecture and how they interact.</p>

    <p>Taking inspiration from RNA memory transfer in Planarians and Aplysia californica, we augment the NCA hidden state with a "private tape".
    Instead of extending the classic NCA model by appending the tape to the hidden states, we choose to sacrifice hidden states by privatizing them, this ensures that any
    improvements seen are not due to an increase in model size. The theory here is that the private tape augmentation can be exploited to encode different modalities of behaviour,
    such as growing different shapes or representing different calculations.</p>

    <figure style="text-align: center; margin: 2rem 0;"><img playsinline src="figures/gene.drawio.svg"; id="figure-augment"
          style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>NCA augmentation through gene embedding channels.</figcaption>

    <p>We chose to encode different "primitives" in the tape through binary representation. These primitives can consist of simple shapes such as convex polygons or
    more complex, convex, compound shapes such as body segments of a lizard emoji.</p>
    <figure style="text-align: center; margin: 2rem 0;"><img playsinline src="figures/embedding.drawio.svg"; id="figure-embed"
          style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption> Binary embedding of different primitives.</figcaption>

    <p>The tape length has to be chosen such that 2^gene_channels is greater or equal to the number of primitives. This ensures that there are enough
    distinct binary encoding for each primitive. However, due to reasons that will be discussed later, it is often preferable to have a buffer of genes that are not used
    in the binary encoding. There is a delicate balance between the number of gene bits and shared hidden channels that needs to be reached as privatisation of channels
    ensures a performance penalty (see Appendix 1.). </p>

    <figure style="text-align: center; margin: 2rem 0;" id="figure-embedliz"><img playsinline src="figures/LizEmbeddings.drawio.svg";
          style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption> Binary embedding of different primitives.</figcaption>



    <a class="marker" href="#section-2.1" id="section-2.1"></a>
    <h3>GeneCA</h3>


    <p>The first model (<a href="#figure-div" class="figure-link" data-target="figure-div"></a>), which we choose to name GeneCA, is tasked with learning the primitive embedding. It takes
    inspiration form the original NCA <d-cite key="mordvintsev2020growing"></d-cite> and is extended to also include a laplacian convolution filter as found in <d-cite key="placeholder"></d-cite>. Notably,
        the parameters only produce a partial cell-state update-vector that comprises all non-gene channels. The gene channels are cloned and appended to the update vector after the stochastic
    update step to prevent degradation over time. This leads to no change or propagation of gene channel information throughout the NCA cell.</p>

      <figure style="text-align: center; margin: 2rem 0;" id="figure-div">
    <img playsinline src="figures/Gene.drawio.svg" style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" />
    <figcaption>One step of the GeneCA</figcaption>
    </figure>

    <
    <a class="marker" href="#section-2.2" id="section-2.2"></a>
    <h3>GenePropCA</h3>

    <p>The GenePropCA model (<a href="#GeneProp" class="figure-link" data-target="GeneProp"></a>) is tasked with exploiting the gene embedding learned by the GeneCA.
    By conditioning the primitive growth in the GeneCA to specific embedding, these embeddings now carry latent information about the primitives. We assume that the latent information
    in each embedding can be modified to produce out-of-training behaviour, thus allowing the GenePropCA to both propagate and modify the genes to achieve a desired goal.
    The architecture of the GenePropCA is similar to that of the GeneCA, where the neural network parameters produce a partial cell state update. In this case, only the genes are updated. Like in
    the GeneCA, the un-updated cell states are cloned and appended after the asynchronous partial update, leading to the GenePropCA having no influence over non=gene channels. </p>

    <figure style="text-align: center; margin: 2rem 0;" id="GeneProp"><img playsinline src="figures/GeneProp1.drawio.svg"
      style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>One step of the GenePropCA</figcaption>




    <a class="marker" href="#section-2.3" id="section-2.3"></a>
    <h3>Ensemble</h3>

    

    <p>The ensemble model uses the GeneCA and GenePropCA to produce the final morphology. The GeneCA works without the GenePropCA and will produce the primitives. The
    GenePropCA is dependent on the GeneCA as its parameters are trained to manipulate the GeneCA dynamics. At step N, the state of the CA is passed to the GeneCA, where it only modifies the visible and hidden channels
    to produce an intermediate state, the intermediate step is then passed to the GenePropCA, where only the gene encoding channels are modified to produce step N+1. The idea here is for the
    GenePropCA to learn to exploit the gene embedded dynamics of the GeneCA to produce more complex morphologies than that found in the GeneCA.</p>

    <figure style="text-align: center; margin: 2rem 0;"><img playsinline src="figures/Enseble.drawio.svg"
      style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>One step of the ensemble, GeneCA + GenePropCA</figcaption>


    <a class="marker" href="#section-3" id="section-3"></a>
    <h2>Hierarchical Growth Task --> I think this section should go before models</h2>

    <p>The traditional NCAs presented in <d-cite key="mordvintsev2020growing">"</d-cite> and extended upon in <d-cite key="placeholder, placeholder"></d-cite> use the neural-network
    parameters to encode the desired behaviour. In effect, the neural-network can be seen as the genome for the morphology, where for each distinct morphology a new NCA needs to be trained.
    Intern, this makes it particularly difficult to have coexisting morphologies, or even just coexisting dynamics, running on the same lattice, as the multiple NCAs end up interfering with each-other.</p>

    <p>Our model presents a possible solution to this problem ... <-- finish this paragraph</p>

    <a class="marker" href="#section-3.1" id="section-3.1"></a>
    <h3>Growing Coexisting Primitives</h3>

    <p>The first step in the hierarchical growth task is to grow coexisting morphologies. In effect, this means to grow multiple distinct morphologies using the same set of NCA parameters. Much like te original growth task, the
    multiple morphologies should be bounded and stable across time, with their shape unchanging once fully generated. </p>

    <a class="marker" href="#section-3.2" id="section-3.2"></a>
    <h3>Growing Morphologies from Primitives</h3>

    <a class="marker" href="#section-4" id="section-4"></a>
    <h2>Training Procedure</h2>
    <p>A description of the training procedure. Talk about two training phases, the special pooling method to train multiple DNA at once
    and how the GeneNCa Weights are frozen when training the GeneProp NCA</p>

    <a class="marker" href="#section-4.1" id="section-4.1"></a>
    <h3>GeneCA Training</h3>
    <p>GeneCA training is similar to the pool-training procedure presented in <d-cite key="mordvintsev2020growing"></d-cite>. However, to enable the gene encoding of multiple primitives,
    each gene-primitive pair is given its own pool to sample from and update. Additionally, the target image becomes a target batch consisting of n-repetitions of each image,
    where n is a factor of the batch size. It is important to keep the batch size as a multiple of the number of primitives to avoid training bias towards one primitive.</p>
    <figure style="text-align: center; margin: 2rem 0;"><img playsinline src="figures/Training.drawio.svg"
      style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Training loop for multi-image batch training</figcaption>

    <a class="marker" href="#section-4.2" id="section-4.2"></a>
    <h3>GenePropCA Training</h3>
    <p>GenePropCA training uses the same batch training technique as the GeneCA, we usually only train a single morphology, however multiple morphologies can be trained by
    sacrificing more channels to act as "meta genes". These meta genes are unaffected by both the GeneCA and GenePropCA. During the training of the GenePropCA the GeneCA weights are frozen,
    though their gradient contribution during the growth process is still used when backpropagating the loss to the GenePropCA. This ensures the GenePropCA's dynamics are
    conditioned on those of the GeneCA.</p>
     <figure style="text-align: center; margin: 2rem 0;"><img playsinline src="figures/training_prop.drawio.svg"
      style="width:100%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Training loop for GenePropCA</figcaption>
    <a class="marker" href="#section-5" id="section-5"></a>
    <h2>Results</h2>
    <p>The model was tested with different primitives, target images and configuration. Below are the results of those experiments. Generally, the NCA has a size of 30 x 30, there are 16 channels in total of which the first four are the alpha value and the three color channels. Of the remaining 12 hidden channels, eight channels were privatized, i.e. could be read but not be altered by the GeneCA. </p>

    <a class="marker" href="#section-5.1" id="section-5.1"></a>
    <h3>Growing Coexisting Primitives </h3>

    <p>Three primitives were chosen as target shapes: A blue square, a green circle and a red triangle. Those primitives have a corresponding one-hot encoding in the private tape. The geneCA was trained to update the public channels of the CA such that the right primitive is formed around a cell with the corresponding encoding. It is important to note that there is no gene propagation at this point, only the update of the public channels that the geneCA calculates based on the available private and public channels. </p>
    <p>During test time, cells of the CA are picked as seed cells, and their private tape is altered. </p>

    <p><a href="#growing-prims" class="figure-link" data-target="growing-prims"></a> shows how the binary encoding of the three primitives is assigned to three different cells in the CA, with the distance between them being great enough to avoid interactions between cells belonging to different primitives. Starting from the seed cell, the shapes and their color form over a number of update steps. Afterwards, they remain stable. </p>
    <figure style="text-align: center; margin: 2rem 0;" id="growing-prims"><video loop autoplay playsinline muted width="640px"; src="figures/Primitives.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing simple primitives.</figcaption>
    <p> <a href="#individuality-demo" class="figure-link" data-target="individuality-demo"></a> shows what happens if seed cells are placed in such proximity to each other that the resulting primitives would normally overlap.
        As can be seen, the shapes remain largely distinct. Especially shapes of the same kind have neither overlap nor mixing and instead a border
        can be visually seen. Circles placed in proximity to each other can for example be seen to form a comb-like structure (top of <a href="#individuality-demo" class="figure-link" data-target="individuality-demo"></a>).
        If shapes of different kinds meet, the distinction is not always as clear and some interactions between different primitives can lead to a
        mixing of colors, as can be seen in the bottom of <a href="#individuality-demo" class="figure-link" data-target="individuality-demo"></a>. Still, a distinction can be made and no primitive takes over another primitive.
        This happens without such cases occurring during training. </p>
    <figure style="text-align: center; margin: 2rem 0;" id="individuality-demo"><video loop autoplay playsinline muted width="640px"; src="figures/Individuals.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Untrained behaviour: primitives displaying strong individuality.</figcaption>

    <p>Only the three one-hot encodings were used during training, but it is possible to deviate from this during test time and to use different binary arrays as the private encodings of the seed cell.
        This essentially means that there is a mixture of genes. As can be seen in <a href="#primitive-mixing" class="figure-link" data-target="primitive-mixing"></a>, this leads to the growth of corresponding mixed forms. It can be seen that the shape of those forms is a
        distorted overlap of the primitives while the color ranges from the pure color of the primitives to the mix of the two colors. The primitives dominate the developing form in those areas where
        the other primitive is not growing, hence the combination of circle and square leads to most mixing. After a developmental period, the forms remain stable. This stability remains for any form of
        encoding mixing and seems to be bound bythe maximum size of the primitives. </p>

    <figure style="text-align: center; margin: 2rem 0;" id="primitive-mixing"><video loop autoplay playsinline muted width="640px"; src="figures/Mixed.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Untrained behaviour: out-of-training generative capabilities from mixing genes.</figcaption>
    <p>The experiments were repeated with body parts of the lizard image as primitives as can be seen in <a href="#body-part-prims" class="figure-link" data-target="body-part-prims"></a>. As those were more than three parts, the encoding is not one-hot anymore. As before, placing a seed cell with the corresponding encoding
        leads to the growth and stable persistence of primitives, even though those have more complex shapes and colorings. </p>

    <figure style="text-align: center; margin: 2rem 0;" id="body-part-prims"><video loop autoplay playsinline muted width="640px"; src="figures/body_parts.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Lizard body parts primitives.</figcaption>
    <p>Lastly, very simple unicolor vertical and horizontal lines were used as primitive as is depicted in <a href="#line-prims" class="figure-link" data-target="line-prims"></a>. This is the setup for later experiments. </p>

     <figure style="text-align: center; margin: 2rem 0;" id="line-prims"><video loop autoplay playsinline muted width="640px"; src="figures/horiz_vert.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Horizontal and vertical line primitives.</figcaption>




    <a class="marker" href="#section-5.2" id="section-5.2"></a>
    <h3>Growing Morphologies from Primitives </h3>

    <p>In the next step, the genepropCA was included. The attempt was to grow whole morphologies, while the geneCA weights where frozen on growing primitives.</p>
    <p>In the lizard example, the genepropCA was trained as described above with the initial state being the seed for the torso primitive and the geneCA being trained
        on parts of the whole lizard. As can be seen in <a href="#liz-from-parts" class="figure-link" data-target="liz-from-parts"></a>, the torso of the lizard is grown first, but the CA then continues to grow the limbs, tail and head. Deactivating
        the genepropCA after the lizard is finished growing does not lead to a collapse, rather the lizard maintains its shape under the control of the geneCA. </p>
    <figure style="text-align: center; margin: 2rem 0;" id="liz-from-parts"><video loop autoplay playsinline muted width="640px"; src="figures/Growing_from_torso.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing the lizard morphology from the torso.</figcaption>

    <p>The experiment was repeated, this time choosing the circle, square and triangle as primitives and the blue circle as the seed cell during the genepropCA training. This was successful, as can be seen
        in <a href="#liz-from-shapes" class="figure-link" data-target="liz-from-shapes"></a>. Even if the geneCA is not trained on all primitives occurring in the final lizard or even on primitives not derived from the target image at all, the genepropCA
        is able to generalize and facilitate gene propagation that leads to the growth of the lizard, albeit with less quality as in the case described above for <a href="#liz-from-parts" class="figure-link" data-target="liz-from-parts"></a>. <a href="#liz-diff-start" class="figure-link" data-target="liz-diff-start"></a>
        shows that the choice of the seed cell does indeed matter, as the lizard will only grow successfully if the exact same seed as in the training of the genepropCA is used.  </p>
    <p>Further experiments showed that different seeds, which were not used as primitives during the training of the geneCA, can be used to train the genepropCA to grow a lizard.  </p>
    <figure style="text-align: center; margin: 2rem 0;" id="liz-from-shapes"><video loop autoplay playsinline muted width="640px"; src="figures/GrowingLizardFast.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing the lizard from basic morphologies.</figcaption>
    <figure style="text-align: center; margin: 2rem 0;" id="liz-diff-start"><video loop autoplay playsinline muted width="640px"; src="figures/GrowingMorpho_multi.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>The lizard will not grow form other primitives.</figcaption>

    <p><a href="#grow-frac" class="figure-link" data-target="grow-frac"></a> depicts an experiment in which the simple primitives of unicolor vertical and horizontal lines are combined into a fractal with satisfying performance. This shows that the model can combine simple and few primitives into more complex
        form consisting of many primitives in addition to combining complex and many primitives into less complex forms consisting of few primitives, as was done before with the lizard. </p>

    <figure style="text-align: center; margin: 2rem 0;" id="grow-frac"><video loop autoplay playsinline muted width="640px"; src="figures/fract.webm" style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);"/></figure><figcaption>Growing a fractal</figcaption>

    <a class="marker" href="#section-5.3" id="section-5.3"></a>
    <h3>Growing Coexisting Morphologies from Primitives </h3>

    <a class="marker" href="#section-5.4" id="section-5.4"></a>
    <h3>Moving Primitives </h3>

    <p>In contrast to the relatively simple task of growing morphologies, we wanted to test if the GenePropCA could exploit the embedding and learn the dynamics of
    a complex system. For this we chose to replicate the dynamics of a Lenia glider. Lenia itself is a form of continuous CA that can exhibit remarkable complexity.
    We chose a glider (<a href="#originalLenia" class="figure-link" data-target="originalLenia"></a>)  whose dynamics where no trivial, where learning to replicate it
    would take more than simply memorising a simple pattern of motion. The GeneCA was trained on the first frame of the Lenia video. The GenePropCA was trained on a
    quasi curriculum style learning, where at certain checkpoints additional frames of the video are inserted into the training set. It is always trained from the first frame
    t0 the last frame of the training set in order, and loss was accumulated across all frames before backpropagation. The frame-by-frame loss accumulation is important here
    since, unlike growing morphologies, the time evolution of the NCA from state to state is important. As a comparison a standard NCA was trained using the same method, the parameter count
    of the standard NCA was selected such that it equaled the sum of total parameters between the GeneCA and the GenePropCA.</p>

    <figure style="text-align: center; margin: 2rem 0;" id="originalLenia"><img playsinline src="figures/original_lenia.gif"
      style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Original Lenia video.</figcaption>

    <figure style="text-align: center; margin: 2rem 0;" id="standardNCA"><img playsinline src="figures/standard_nca.gif"
      style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Standard NCA trained to replicate the video.</figcaption>

    <figure style="text-align: center; margin: 2rem 0;" id="movingGene"><img playsinline src="figures/Gene_ca_moving.gif"
      style="width:60%; border: 0px solid rgba(0, 0, 0, 0.2);" /></figure><figcaption>Our method trained to replicate the video.</figcaption>

    <a class="marker" href="#section-6" id="section-6"></a>
    <h2>Related Work</h2>

    <a class="marker" href="#section-7" id="section-7"></a>
    <h2>Discussion</h2>
    <p>A discussion of the results, their significance  and meaning.</p>

    <a class="marker" href="#section-8" id="section-8"></a>
    <h2>Conclusion </h2>
    <p>Conclusion to wrap up the paper summarising what was done and how the results are significant</p>



    <!-- if something breaks later on, add back script section form ref.html -->


  </d-article>