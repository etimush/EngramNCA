{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "260c99ee311850a6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from geomloss import SamplesLoss\n",
    "import NCA.utils as utils\n",
    "from NCA.NCA import *\n",
    "from NCA.utils import  natural_keys\n",
    "import csv\n",
    "import os"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Whether Graphs Have a Normal Scale or Log Scale "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bf58b07a8bc1f669"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "NORMAL = True"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8d619d2de1adc6ca"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Graph for Final Training Loss Compared to Masking Level"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1a26a0631b8cfbdd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"Saved_Data/Butterfly\"  #<--- Make sure its correct \n",
    "final_log = []\n",
    "regrowth_log = []\n",
    "# plt the min loss for each model compared to masking\n",
    "x_axis = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "colors = [\"r\", \"g\", \"b\"]\n",
    "ncas = [\"Reduced\", \"Pre-Conv Artifact\", \"Post-Conv Artifact\"]\n",
    "plt.figure(4)\n",
    "\n",
    "for id, (root, subdirs, files) in enumerate(os.walk(path, topdown=True)):\n",
    "    means = []\n",
    "    stds=[]\n",
    "    if len(files) != 0:\n",
    "        files.sort(key=natural_keys)\n",
    "        for idx, file in enumerate(files):\n",
    "            data = np.load(root+ \"/\" +file)\n",
    "            if NORMAL:\n",
    "                data1 = np.mean(np.exp(np.min(data)))/ 50**2\n",
    "            else:\n",
    "                data1 = np.min(data)\n",
    "            data2 = np.std(data[-1:])\n",
    "            print(file)\n",
    "            means.append(data1)\n",
    "            stds.append(data2)\n",
    "        means = np.asarray(means)\n",
    "        final_log.append(means)\n",
    "        stds = np.asarray(stds)\n",
    "        plt.plot(x_axis, means, color = colors[id-1], label=ncas[id-1])\n",
    "        plt.ylabel('min(mean final loss)')\n",
    "        plt.xlabel('N masked layers')\n",
    "        plt.legend()\n",
    "        plt.grid(True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aadf673e667e3242"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Graph for Mean Regrowth Loss Compared to Masking Level "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6058bf360fa97a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = \"Regrow_exp_data/Butterfly\"\n",
    "x_axis = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "colors = [\"b\", \"g\", \"r\"]\n",
    "ncas = [ \"Post-Conv Artifact\", \"Pre-Conv Artifact\", \"Reduced\"]\n",
    "plt.figure(3)\n",
    "for id, (root, subdirs, files) in enumerate(os.walk(path, topdown=True)):\n",
    "    if len(files) != 0:\n",
    "        for idx, file in enumerate(files):\n",
    "            data = np.load(root+ \"/\" +file)\n",
    "            if NORMAL:\n",
    "                data1 = np.exp(np.mean(data, axis=1))/ 50**2\n",
    "            else:\n",
    "                data1 = np.mean(data, axis=1)\n",
    "            data2 = np.std(data, axis=1)\n",
    "            regrowth_log.insert(0, data1)\n",
    "            print(file )\n",
    "            plt.plot(x_axis, data1, color = colors[idx], label=ncas[idx])\n",
    "            plt.ylabel('mean loss after regrowth')\n",
    "            plt.xlabel('N masked layers')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ad443c74d3f26a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Produces the CSV Comparing NCA through Gram Loss "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2379706e5abbbe26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path_masked = \"Trained_models/Lizard/Masked\" #<--- first set of models to compare \n",
    "path_dummy = \"Trained_models/Lizard/Masked\" #<--- second set of models to compare, can be same \n",
    "dummy_files = os.listdir(path_dummy)\n",
    "masked_files = os.listdir(path_masked)\n",
    "masked_files.sort(key=natural_keys)\n",
    "dummy_files.sort(key=natural_keys)\n",
    "mat = []\n",
    "loss_fn = SamplesLoss(\"sinkhorn\", p=2, blur=0.005)\n",
    "for df in dummy_files:\n",
    "    df = path_dummy + \"/\" + df\n",
    "    nca1 = DummyVCA(16, 96, 0)\n",
    "    nca1.load_state_dict(torch.load(df))\n",
    "    nca1.cuda().eval()\n",
    "    sum_losses = []\n",
    "    for mf in masked_files:\n",
    "        mf = path_masked + \"/\" + mf\n",
    "        nca2 = DummyVCA(16,96,0)\n",
    "        nca2.load_state_dict(torch.load(mf))\n",
    "        nca2.cuda().eval()\n",
    "        loss = 0\n",
    "        for (name1,param1), (name2,param2) in zip(nca1.named_parameters(), nca2.named_parameters()):\n",
    "            if len(param1.shape) >1:\n",
    "                loss = loss + torch.nn.functional.mse_loss(utils.gram_matrix(param1.data), utils.gram_matrix(param2.data)).item()\n",
    "\n",
    "        sum_losses.append(loss)\n",
    "    mat.append(sum_losses)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc86a25898aefd96"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Creates the Path and Saves CSV"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb049a98a8bf0c95"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "csv_path = \"CSVs\"\n",
    "if not os.path.exists(csv_path):\n",
    "    os.makedirs(csv_path)\n",
    "    print(f\"Path: {csv_path} created\")\n",
    "else: \n",
    "    print(f\"Path: {csv_path} already exists, all OK!\")\n",
    "    \n",
    "    \n",
    "file_path = \"/inter_image_gram.csv\" #<--- name of csv \n",
    "with open(csv_path+file_path, \"w+\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv, delimiter=',')\n",
    "    csvWriter.writerows(mat)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a86408639c57cee"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pearson Correlation Coef Between Regrowth Loss and Training Loss "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e02a08872470e01"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for final_l, regrowth_log in zip(final_log, regrowth_log):\n",
    "    print(np.corrcoef(final_l, regrowth_log))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e0f0f3f53cfbe98"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
